{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ—‘ï¸ Identify Redundant Playlists & Reorganization\n",
        "\n",
        "Analyze your playlists to identify **redundant playlists** that can be safely deleted or merged without losing information.\n",
        "\n",
        "**What this notebook does:**\n",
        "- ğŸ” Finds playlists with high track overlap (duplicates/near-duplicates)\n",
        "- ğŸ“Š Identifies playlists that are subsets of other playlists\n",
        "- ğŸ¯ Suggests playlists safe to delete\n",
        "- ğŸ“‹ Proposes a reorganized library structure\n",
        "- ğŸ’¡ Recommends consolidation strategies\n",
        "\n",
        "**Prerequisites:** \n",
        "- Run `01_sync_data.ipynb` to download your library\n",
        "- Run `04_analyze_listening_history.ipynb` (optional) to enable listening-based redundancy detection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1ï¸âƒ£ Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "âœ… Project root: /Users/aryamaan/Desktop/Projects/spotim8\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "%pip install -q pandas pyarrow tqdm\n",
        "\n",
        "# Add project to path\n",
        "import sys\n",
        "from pathlib import Path\n",
        "PROJECT_ROOT = Path(\"..\").resolve()\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "print(f\"âœ… Project root: {PROJECT_ROOT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aryamaan/Desktop/Projects/spotim8/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ Data directory: /Users/aryamaan/Desktop/Projects/spotim8/data\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, Counter\n",
        "from typing import Dict, List, Set, Tuple\n",
        "from tqdm.auto import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from spotim8.analysis import LibraryAnalyzer, PlaylistSimilarityEngine\n",
        "\n",
        "# Data directory\n",
        "DATA_DIR = PROJECT_ROOT / \"data\"\n",
        "print(f\"ğŸ“ Data directory: {DATA_DIR.resolve()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2ï¸âƒ£ Load Library Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Loaded 626 playlists, 5,280 tracks\n",
            "âœ… Loaded 196 owned playlists\n",
            "ğŸ“Š Total playlist-track links: 45,598\n",
            "   (Excluded Liked Songs from analysis)\n",
            "\n",
            "ğŸ“‹ Analyzing 195 playlists for redundancy...\n"
          ]
        }
      ],
      "source": [
        "# Load all data (owned playlists only for analysis)\n",
        "analyzer = LibraryAnalyzer(DATA_DIR).load()\n",
        "\n",
        "# Get owned playlists\n",
        "playlists = analyzer.playlists_all[analyzer.playlists_all['is_owned'] == True].copy()\n",
        "playlist_tracks = analyzer.playlist_tracks_all[\n",
        "    analyzer.playlist_tracks_all['playlist_id'].isin(playlists['playlist_id'])\n",
        "].copy()\n",
        "\n",
        "print(f\"âœ… Loaded {len(playlists)} owned playlists\")\n",
        "print(f\"ğŸ“Š Total playlist-track links: {len(playlist_tracks):,}\")\n",
        "\n",
        "# Exclude Liked Songs from redundancy analysis (it's the master playlist)\n",
        "liked_id = analyzer.liked_songs_id\n",
        "if liked_id:\n",
        "    playlists = playlists[playlists['playlist_id'] != liked_id].copy()\n",
        "    print(f\"   (Excluded Liked Songs from analysis)\")\n",
        "\n",
        "print(f\"\\nğŸ“‹ Analyzing {len(playlists)} playlists for redundancy...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3ï¸âƒ£ Build Playlist Track Sets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Building track sets: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 195/195 [00:01<00:00, 187.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Built track sets for 193 playlists\n",
            "ğŸ“Š Total unique tracks across all playlists: 5,280\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Build track sets for each playlist\n",
        "playlist_track_sets: Dict[str, Set[str]] = {}\n",
        "playlist_info = {}\n",
        "\n",
        "for pid in tqdm(playlists['playlist_id'], desc=\"Building track sets\"):\n",
        "    tracks = set(playlist_tracks[playlist_tracks['playlist_id'] == pid]['track_id'].unique())\n",
        "    playlist_track_sets[pid] = tracks\n",
        "    \n",
        "    info = playlists[playlists['playlist_id'] == pid].iloc[0]\n",
        "    playlist_info[pid] = {\n",
        "        'name': info.get('name', 'Unknown'),\n",
        "        'track_count': len(tracks),\n",
        "        'is_liked_songs': info.get('is_liked_songs', False),\n",
        "    }\n",
        "\n",
        "print(f\"âœ… Built track sets for {len(playlist_track_sets)} playlists\")\n",
        "print(f\"ğŸ“Š Total unique tracks across all playlists: {len(set().union(*playlist_track_sets.values())):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4ï¸âƒ£ Find Redundant Playlists\n",
        "\n",
        "We'll identify redundancy using multiple criteria:\n",
        "1. **Exact duplicates** - Same tracks\n",
        "2. **Subsets** - All tracks in one playlist are in another\n",
        "3. **High overlap** - Very similar track sets (>90% overlap)\n",
        "4. **Near-duplicates** - High similarity with minor differences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ” Analyzing playlist pairs...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Comparing playlists: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 193/193 [00:00<00:00, 454.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… Analysis complete!\n",
            "   Exact duplicates: 0\n",
            "   Subsets: 88\n",
            "   High overlap (>90%): 0\n",
            "   Near duplicates (80-90%): 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def jaccard_similarity(set1: Set, set2: Set) -> float:\n",
        "    \"\"\"Calculate Jaccard similarity (intersection / union).\"\"\"\n",
        "    if not set1 and not set2:\n",
        "        return 1.0\n",
        "    if not set1 or not set2:\n",
        "        return 0.0\n",
        "    intersection = len(set1 & set2)\n",
        "    union = len(set1 | set2)\n",
        "    return intersection / union if union > 0 else 0.0\n",
        "\n",
        "def overlap_ratio(set1: Set, set2: Set) -> Tuple[float, float]:\n",
        "    \"\"\"Calculate overlap ratios in both directions.\n",
        "    \n",
        "    Returns:\n",
        "        (ratio of set1 in set2, ratio of set2 in set1)\n",
        "    \"\"\"\n",
        "    if not set1 or not set2:\n",
        "        return (0.0, 0.0)\n",
        "    intersection = len(set1 & set2)\n",
        "    return (intersection / len(set1), intersection / len(set2))\n",
        "\n",
        "# Find redundant playlists\n",
        "redundant_groups = []\n",
        "exact_duplicates = []\n",
        "subsets = []  # (subset_playlist, superset_playlist)\n",
        "high_overlap = []  # (>90% similarity)\n",
        "near_duplicates = []  # (80-90% similarity)\n",
        "\n",
        "playlist_ids = list(playlist_track_sets.keys())\n",
        "\n",
        "print(\"ğŸ” Analyzing playlist pairs...\")\n",
        "for i in tqdm(range(len(playlist_ids)), desc=\"Comparing playlists\"):\n",
        "    pid1 = playlist_ids[i]\n",
        "    set1 = playlist_track_sets[pid1]\n",
        "    \n",
        "    if not set1:  # Skip empty playlists\n",
        "        continue\n",
        "    \n",
        "    for j in range(i + 1, len(playlist_ids)):\n",
        "        pid2 = playlist_ids[j]\n",
        "        set2 = playlist_track_sets[pid2]\n",
        "        \n",
        "        if not set2:  # Skip empty playlists\n",
        "            continue\n",
        "        \n",
        "        # Check for exact duplicates\n",
        "        if set1 == set2:\n",
        "            exact_duplicates.append((pid1, pid2))\n",
        "            continue\n",
        "        \n",
        "        # Check for subsets\n",
        "        if set1.issubset(set2):\n",
        "            subsets.append((pid1, pid2, len(set1), len(set2)))\n",
        "        elif set2.issubset(set1):\n",
        "            subsets.append((pid2, pid1, len(set2), len(set1)))\n",
        "        \n",
        "        # Calculate similarity\n",
        "        jaccard = jaccard_similarity(set1, set2)\n",
        "        overlap1, overlap2 = overlap_ratio(set1, set2)\n",
        "        \n",
        "        if jaccard > 0.9:\n",
        "            high_overlap.append((pid1, pid2, jaccard, overlap1, overlap2))\n",
        "        elif jaccard > 0.8:\n",
        "            near_duplicates.append((pid1, pid2, jaccard, overlap1, overlap2))\n",
        "\n",
        "print(f\"\\nâœ… Analysis complete!\")\n",
        "print(f\"   Exact duplicates: {len(exact_duplicates)}\")\n",
        "print(f\"   Subsets: {len(subsets)}\")\n",
        "print(f\"   High overlap (>90%): {len(high_overlap)}\")\n",
        "print(f\"   Near duplicates (80-90%): {len(near_duplicates)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… No exact duplicates found\n"
          ]
        }
      ],
      "source": [
        "# Display exact duplicates\n",
        "if exact_duplicates:\n",
        "    print(\"=\" * 80)\n",
        "    print(\"ğŸ”„ EXACT DUPLICATES (Same tracks, can delete one)\")\n",
        "    print(\"=\" * 80)\n",
        "    for pid1, pid2 in exact_duplicates:\n",
        "        info1 = playlist_info[pid1]\n",
        "        info2 = playlist_info[pid2]\n",
        "        print(f\"\\nğŸ“‹ {info1['name']} ({info1['track_count']} tracks)\")\n",
        "        print(f\"   âš¡ Duplicate of: {info2['name']} ({info2['track_count']} tracks)\")\n",
        "        print(f\"   ğŸ’¡ Recommendation: Delete one (keep the one with better name)\")\n",
        "else:\n",
        "    print(\"âœ… No exact duplicates found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "ğŸ“¦ SUBSETS (Fully contained in another playlist - SAFE TO DELETE)\n",
            "================================================================================\n",
            "\n",
            "ğŸ“Š Found 88 playlists that are subsets of others:\n",
            "\n",
            " Subset Playlist  Subset Tracks      Contained In  Superset Tracks         Coverage\n",
            "  AJFindsOther23            943         AJFinds23             1233 943/1233 (76.5%)\n",
            "  AJFindsOther22            836         AJFinds22             1150 836/1150 (72.7%)\n",
            "  AJFindsOther21            810         AJFinds21             1310 810/1310 (61.8%)\n",
            " AJFindsHipHop21            452       AJamHip-Hop             1557 452/1557 (29.0%)\n",
            " AJFindsHipHop21            452         AJFinds21             1310 452/1310 (34.5%)\n",
            "  AJFindsOther24            245         AJFinds24              434  245/434 (56.5%)\n",
            " AJFindsHipHop23            223         AJFinds23             1233 223/1233 (18.1%)\n",
            " AJFindsHipHop23            223       AJamHip-Hop             1557 223/1557 (14.3%)\n",
            " AJFindsHipHop22            218         AJFinds22             1150 218/1150 (19.0%)\n",
            " AJFindsHipHop22            218       AJamHip-Hop             1557 218/1557 (14.0%)\n",
            " OtherFindsNov25            200      AJFindsNov25              228  200/228 (87.7%)\n",
            " AJFindsHipHop24            146       AJamHip-Hop             1557  146/1557 (9.4%)\n",
            " AJFindsHipHop24            146         AJFinds24              434  146/434 (33.6%)\n",
            "  AJFindsDance22             96         AJFinds22             1150   96/1150 (8.3%)\n",
            " OtherFindsOct25             71      AJFindsOct25               89    71/89 (79.8%)\n",
            "  AJFindsDance23             67         AJFinds23             1233   67/1233 (5.4%)\n",
            " OtherFindsAug25             67      AJFindsAug25              153   67/153 (43.8%)\n",
            " DanceFindsAug25             52    AJamElectronic              481   52/481 (10.8%)\n",
            " DanceFindsAug25             52      AJFindsAug25              153   52/153 (34.0%)\n",
            " OtherFindsMay25             48      AJFindsMay25               81    48/81 (59.3%)\n",
            "  AJFindsDance21             48         AJFinds21             1310   48/1310 (3.7%)\n",
            "  AJFindsDance24             43         AJFinds24              434    43/434 (9.9%)\n",
            " OtherFindsApr25             40      AJFindsApr25               72    40/72 (55.6%)\n",
            " OtherFindsDec25             38      AJFindsDec25               88    38/88 (43.2%)\n",
            " DanceFindsJul25             36    AJamElectronic              481    36/481 (7.5%)\n",
            " DanceFindsJul25             36      AJFindsJul25               90    36/90 (40.0%)\n",
            " OtherFindsJul25             35      AJFindsJul25               90    35/90 (38.9%)\n",
            "HipHopFindsAug25             34      AJFindsAug25              153   34/153 (22.2%)\n",
            "HipHopFindsAug25             34       AJamHip-Hop             1557   34/1557 (2.2%)\n",
            " OtherFindsSep25             32      AJFindsSep25               69    32/69 (46.4%)\n",
            "HipHopFindsJun25             30       AJamHip-Hop             1557   30/1557 (1.9%)\n",
            " OtherFindsJun25             30      AJFindsJun25               78    30/78 (38.5%)\n",
            "HipHopFindsJun25             30      AJFindsJun25               78    30/78 (38.5%)\n",
            " DanceFindsDec25             28      AJFindsDec25               88    28/88 (31.8%)\n",
            " DanceFindsSep25             24      AJFindsSep25               69    24/69 (34.8%)\n",
            " DanceFindsSep25             24    AJamElectronic              481    24/481 (5.0%)\n",
            "HipHopFindsDec25             22      AJFindsDec25               88    22/88 (25.0%)\n",
            "HipHopFindsDec25             22       AJamHip-Hop             1557   22/1557 (1.4%)\n",
            " DanceFindsMay25             20      AJFindsMay25               81    20/81 (24.7%)\n",
            " DanceFindsMay25             20    AJamElectronic              481    20/481 (4.2%)\n",
            " DanceFindsApr25             19      AJFindsApr25               72    19/72 (26.4%)\n",
            " DanceFindsApr25             19    AJamElectronic              481    19/481 (4.0%)\n",
            "HipHopFindsJul25             19      AJFindsJul25               90    19/90 (21.1%)\n",
            "HipHopFindsJul25             19       AJamHip-Hop             1557   19/1557 (1.2%)\n",
            " DanceFindsNov25             19      AJFindsNov25              228    19/228 (8.3%)\n",
            " DanceFindsNov25             19    AJamElectronic              481    19/481 (4.0%)\n",
            " DanceFindsJun25             18      AJFindsJun25               78    18/78 (23.1%)\n",
            " DanceFindsJun25             18    AJamElectronic              481    18/481 (3.7%)\n",
            "HipHopFindsOct25             17      AJFindsOct25               89    17/89 (19.1%)\n",
            "HipHopFindsOct25             17       AJamHip-Hop             1557   17/1557 (1.1%)\n",
            " OtherFindsMar25             14      AJFindsMar25               23    14/23 (60.9%)\n",
            "HipHopFindsMay25             13      AJFindsMay25               81    13/81 (16.0%)\n",
            "HipHopFindsApr25             13      AJFindsApr25               72    13/72 (18.1%)\n",
            "        Marchâ€™24             13     SandTrap ğŸï¸ğŸ‡¹ğŸ‡­              982    13/982 (1.3%)\n",
            "HipHopFindsSep25             13      AJFindsSep25               69    13/69 (18.8%)\n",
            "HipHopFindsApr25             13       AJamHip-Hop             1557   13/1557 (0.8%)\n",
            "HipHopFindsMay25             13       AJamHip-Hop             1557   13/1557 (0.8%)\n",
            "HipHopFindsSep25             13       AJamHip-Hop             1557   13/1557 (0.8%)\n",
            "        Trapsoul             11       Ride the ğŸŒŠ               253    11/253 (4.3%)\n",
            "        Trapsoul             11           StylinğŸ¤™              589    11/589 (1.9%)\n",
            "        Trapsoul             11            Jams ğŸ“              444    11/444 (2.5%)\n",
            "        Trapsoul             11         Sunhop â˜€ï¸              797    11/797 (1.4%)\n",
            "        Trapsoul             11 TrapNeverDies2.0ğŸ‘Š              722    11/722 (1.5%)\n",
            "        Trapsoul             11       HanginThere              326    11/326 (3.4%)\n",
            "        Trapsoul             11        Chill trap              517    11/517 (2.1%)\n",
            "HipHopFindsFeb25             10       AJamHip-Hop             1557   10/1557 (0.6%)\n",
            "HipHopFindsFeb25             10      AJFindsFeb25               13    10/13 (76.9%)\n",
            "HipHopFindsNov25              9       AJamHip-Hop             1557    9/1557 (0.6%)\n",
            "HipHopFindsNov25              9      AJFindsNov25              228     9/228 (3.9%)\n",
            "         Trance               8             GharğŸ¡              394     8/394 (2.0%)\n",
            "         Trance               8            Tekky               284     8/284 (2.8%)\n",
            " OtherFindsJan25              7      AJFindsJan25               11     7/11 (63.6%)\n",
            "HipHopFindsMar25              6      AJFindsMar25               23     6/23 (26.1%)\n",
            "HipHopFindsMar25              6       AJamHip-Hop             1557    6/1557 (0.4%)\n",
            "HipHopFindsJan25              4      AJFindsJan25               11     4/11 (36.4%)\n",
            "HipHopFindsJan25              4       AJamHip-Hop             1557    4/1557 (0.3%)\n",
            "       Pepper ğŸ«‘               3         AJFinds23             1233    3/1233 (0.2%)\n",
            " OtherFindsFeb25              3             Feb25              109     3/109 (2.8%)\n",
            " DanceFindsMar25              3    AJamElectronic              481     3/481 (0.6%)\n",
            " OtherFindsFeb25              3        Chill trap              517     3/517 (0.6%)\n",
            " OtherFindsFeb25              3      AJFindsFeb25               13     3/13 (23.1%)\n",
            " DanceFindsMar25              3      AJFindsMar25               23     3/23 (13.0%)\n",
            " DanceFindsOct25              1    AJamElectronic              481     1/481 (0.2%)\n",
            " DanceFindsOct25              1             GharğŸ¡              394     1/394 (0.3%)\n",
            " DanceFindsOct25              1      AJFindsOct25               89      1/89 (1.1%)\n",
            " DanceFindsOct25              1             Oct25              237     1/237 (0.4%)\n",
            " DanceFindsOct25              1            Tekky               284     1/284 (0.4%)\n",
            " DanceFindsOct25              1       Chill Dance              215     1/215 (0.5%)\n",
            "\n",
            "âœ… 50 playlists can be safely deleted (all tracks are in other playlists)\n"
          ]
        }
      ],
      "source": [
        "# Display subsets (playlists fully contained in others)\n",
        "if subsets:\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ğŸ“¦ SUBSETS (Fully contained in another playlist - SAFE TO DELETE)\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    subset_df = []\n",
        "    for subset_pid, superset_pid, subset_size, superset_size in subsets:\n",
        "        subset_info = playlist_info[subset_pid]\n",
        "        superset_info = playlist_info[superset_pid]\n",
        "        subset_df.append({\n",
        "            'Subset Playlist': subset_info['name'],\n",
        "            'Subset Tracks': subset_size,\n",
        "            'Contained In': superset_info['name'],\n",
        "            'Superset Tracks': superset_size,\n",
        "            'Coverage': f\"{subset_size}/{superset_size} ({100*subset_size/superset_size:.1f}%)\"\n",
        "        })\n",
        "    \n",
        "    df = pd.DataFrame(subset_df)\n",
        "    df = df.sort_values('Subset Tracks', ascending=False)\n",
        "    print(f\"\\nğŸ“Š Found {len(df)} playlists that are subsets of others:\\n\")\n",
        "    print(df.to_string(index=False))\n",
        "    \n",
        "    # Identify unique subset playlists (safe to delete)\n",
        "    safe_to_delete = set([subset_pid for subset_pid, _, _, _ in subsets])\n",
        "    print(f\"\\nâœ… {len(safe_to_delete)} playlists can be safely deleted (all tracks are in other playlists)\")\n",
        "else:\n",
        "    print(\"\\nâœ… No subset playlists found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… No high-overlap playlists found\n"
          ]
        }
      ],
      "source": [
        "# Display high overlap playlists\n",
        "if high_overlap:\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ğŸ¯ HIGH OVERLAP (>90% similarity - Likely redundant)\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    overlap_df = []\n",
        "    for pid1, pid2, jaccard, overlap1, overlap2 in high_overlap:\n",
        "        info1 = playlist_info[pid1]\n",
        "        info2 = playlist_info[pid2]\n",
        "        overlap_df.append({\n",
        "            'Playlist 1': info1['name'],\n",
        "            'Tracks 1': info1['track_count'],\n",
        "            'Playlist 2': info2['name'],\n",
        "            'Tracks 2': info2['track_count'],\n",
        "            'Similarity': f\"{jaccard*100:.1f}%\",\n",
        "            'P1 in P2': f\"{overlap1*100:.1f}%\",\n",
        "            'P2 in P1': f\"{overlap2*100:.1f}%\",\n",
        "        })\n",
        "    \n",
        "    df = pd.DataFrame(overlap_df)\n",
        "    df = df.sort_values('Similarity', ascending=False)\n",
        "    print(f\"\\nğŸ“Š Found {len(df)} playlist pairs with >90% similarity:\\n\")\n",
        "    print(df.to_string(index=False))\n",
        "    \n",
        "    print(\"\\nğŸ’¡ Recommendations:\")\n",
        "    print(\"   - If one playlist is much smaller, consider merging into the larger one\")\n",
        "    print(\"   - If playlists serve different purposes, keep both but remove duplicate tracks\")\n",
        "else:\n",
        "    print(\"\\nâœ… No high-overlap playlists found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "ğŸ”— NEAR-DUPLICATES (80-90% similarity - Review for consolidation)\n",
            "================================================================================\n",
            "\n",
            "ğŸ“Š Top 1 near-duplicate pairs (showing first 20):\n",
            "\n",
            "     Playlist 1  Tracks 1   Playlist 2  Tracks 2 Similarity P1 in P2 P2 in P1\n",
            "OtherFindsNov25       200 AJFindsNov25       228      87.7%   100.0%    87.7%\n",
            "\n",
            "ğŸ’¡ Recommendations:\n",
            "   - Review these pairs manually\n",
            "   - Consider merging if they serve the same purpose\n",
            "   - Keep separate if they have distinct purposes\n"
          ]
        }
      ],
      "source": [
        "# Display near-duplicates\n",
        "if near_duplicates:\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ğŸ”— NEAR-DUPLICATES (80-90% similarity - Review for consolidation)\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    near_df = []\n",
        "    for pid1, pid2, jaccard, overlap1, overlap2 in near_duplicates[:20]:  # Show top 20\n",
        "        info1 = playlist_info[pid1]\n",
        "        info2 = playlist_info[pid2]\n",
        "        near_df.append({\n",
        "            'Playlist 1': info1['name'],\n",
        "            'Tracks 1': info1['track_count'],\n",
        "            'Playlist 2': info2['name'],\n",
        "            'Tracks 2': info2['track_count'],\n",
        "            'Similarity': f\"{jaccard*100:.1f}%\",\n",
        "            'P1 in P2': f\"{overlap1*100:.1f}%\",\n",
        "            'P2 in P1': f\"{overlap2*100:.1f}%\",\n",
        "        })\n",
        "    \n",
        "    df = pd.DataFrame(near_df)\n",
        "    df = df.sort_values('Similarity', ascending=False)\n",
        "    print(f\"\\nğŸ“Š Top {len(df)} near-duplicate pairs (showing first 20):\\n\")\n",
        "    print(df.to_string(index=False))\n",
        "    \n",
        "    if len(near_duplicates) > 20:\n",
        "        print(f\"\\n   ... and {len(near_duplicates) - 20} more pairs\")\n",
        "    \n",
        "    print(\"\\nğŸ’¡ Recommendations:\")\n",
        "    print(\"   - Review these pairs manually\")\n",
        "    print(\"   - Consider merging if they serve the same purpose\")\n",
        "    print(\"   - Keep separate if they have distinct purposes\")\n",
        "else:\n",
        "    print(\"\\nâœ… No near-duplicate playlists found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6ï¸âƒ£ Comprehensive Redundancy Analysis\n",
        "\n",
        "Now let's identify ALL playlists that can be safely deleted or consolidated.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Identified 50 playlists that can be safely deleted/merged\n",
            "ğŸ“Š Total consolidation suggestions: 50\n"
          ]
        }
      ],
      "source": [
        "# Build comprehensive list of playlists safe to delete\n",
        "safe_to_delete = set()\n",
        "consolidation_suggestions = []\n",
        "\n",
        "# 1. Exact duplicates - keep the first one, delete others\n",
        "for pid1, pid2 in exact_duplicates:\n",
        "    # Keep the one with more descriptive name or more tracks\n",
        "    info1 = playlist_info[pid1]\n",
        "    info2 = playlist_info[pid2]\n",
        "    if len(info1['name']) >= len(info2['name']):\n",
        "        safe_to_delete.add(pid2)\n",
        "        consolidation_suggestions.append({\n",
        "            'action': 'delete',\n",
        "            'playlist_id': pid2,\n",
        "            'playlist_name': info2['name'],\n",
        "            'reason': f'Exact duplicate of \"{info1[\"name\"]}\"',\n",
        "            'tracks_lost': 0,\n",
        "            'alternative': info1['name']\n",
        "        })\n",
        "    else:\n",
        "        safe_to_delete.add(pid1)\n",
        "        consolidation_suggestions.append({\n",
        "            'action': 'delete',\n",
        "            'playlist_id': pid1,\n",
        "            'playlist_name': info1['name'],\n",
        "            'reason': f'Exact duplicate of \"{info2[\"name\"]}\"',\n",
        "            'tracks_lost': 0,\n",
        "            'alternative': info2['name']\n",
        "        })\n",
        "\n",
        "# 2. Subsets - safe to delete (all tracks are in superset)\n",
        "for subset_pid, superset_pid, subset_size, superset_size in subsets:\n",
        "    if subset_pid not in safe_to_delete:\n",
        "        subset_info = playlist_info[subset_pid]\n",
        "        superset_info = playlist_info[superset_pid]\n",
        "        safe_to_delete.add(subset_pid)\n",
        "        consolidation_suggestions.append({\n",
        "            'action': 'delete',\n",
        "            'playlist_id': subset_pid,\n",
        "            'playlist_name': subset_info['name'],\n",
        "            'reason': f'All {subset_size} tracks are in \"{superset_info[\"name\"]}\" ({superset_size} tracks)',\n",
        "            'tracks_lost': 0,\n",
        "            'alternative': superset_info['name']\n",
        "        })\n",
        "\n",
        "# 3. High overlap - suggest merging\n",
        "for pid1, pid2, jaccard, overlap1, overlap2 in high_overlap:\n",
        "    info1 = playlist_info[pid1]\n",
        "    info2 = playlist_info[pid2]\n",
        "    \n",
        "    # Determine which to keep (prefer larger or better name)\n",
        "    if info1['track_count'] > info2['track_count']:\n",
        "        keep_pid, delete_pid = pid1, pid2\n",
        "        keep_info, delete_info = info1, info2\n",
        "        missing_tracks = len(playlist_track_sets[pid2] - playlist_track_sets[pid1])\n",
        "    elif info2['track_count'] > info1['track_count']:\n",
        "        keep_pid, delete_pid = pid2, pid1\n",
        "        keep_info, delete_info = info2, info1\n",
        "        missing_tracks = len(playlist_track_sets[pid1] - playlist_track_sets[pid2])\n",
        "    else:\n",
        "        # Same size, keep the one with longer name (usually more descriptive)\n",
        "        if len(info1['name']) >= len(info2['name']):\n",
        "            keep_pid, delete_pid = pid1, pid2\n",
        "            keep_info, delete_info = info1, info2\n",
        "            missing_tracks = len(playlist_track_sets[pid2] - playlist_track_sets[pid1])\n",
        "        else:\n",
        "            keep_pid, delete_pid = pid2, pid1\n",
        "            keep_info, delete_info = info2, info1\n",
        "            missing_tracks = len(playlist_track_sets[pid1] - playlist_track_sets[pid2])\n",
        "    \n",
        "    if delete_pid not in safe_to_delete:\n",
        "        safe_to_delete.add(delete_pid)\n",
        "        consolidation_suggestions.append({\n",
        "            'action': 'merge',\n",
        "            'playlist_id': delete_pid,\n",
        "            'playlist_name': delete_info['name'],\n",
        "            'reason': f'{jaccard*100:.1f}% similar to \"{keep_info[\"name\"]}\"',\n",
        "            'tracks_lost': missing_tracks,\n",
        "            'alternative': f'Merge into \"{keep_info[\"name\"]}\" (add {missing_tracks} missing tracks)'\n",
        "        })\n",
        "\n",
        "print(f\"âœ… Identified {len(safe_to_delete)} playlists that can be safely deleted/merged\")\n",
        "print(f\"ğŸ“Š Total consolidation suggestions: {len(consolidation_suggestions)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "ğŸ“‹ CONSOLIDATION RECOMMENDATIONS\n",
            "================================================================================\n",
            "\n",
            "ğŸ—‘ï¸  SAFE TO DELETE (50 playlists - 0 tracks lost):\n",
            "--------------------------------------------------------------------------------\n",
            "   â€¢ AJFindsDance21\n",
            "     â†’ All 48 tracks are in \"AJFinds21\" (1310 tracks)\n",
            "     â†’ Keep: AJFinds21\n",
            "\n",
            "   â€¢ AJFindsDance22\n",
            "     â†’ All 96 tracks are in \"AJFinds22\" (1150 tracks)\n",
            "     â†’ Keep: AJFinds22\n",
            "\n",
            "   â€¢ AJFindsDance23\n",
            "     â†’ All 67 tracks are in \"AJFinds23\" (1233 tracks)\n",
            "     â†’ Keep: AJFinds23\n",
            "\n",
            "   â€¢ AJFindsDance24\n",
            "     â†’ All 43 tracks are in \"AJFinds24\" (434 tracks)\n",
            "     â†’ Keep: AJFinds24\n",
            "\n",
            "   â€¢ AJFindsHipHop21\n",
            "     â†’ All 452 tracks are in \"AJFinds21\" (1310 tracks)\n",
            "     â†’ Keep: AJFinds21\n",
            "\n",
            "   â€¢ AJFindsHipHop22\n",
            "     â†’ All 218 tracks are in \"AJFinds22\" (1150 tracks)\n",
            "     â†’ Keep: AJFinds22\n",
            "\n",
            "   â€¢ AJFindsHipHop23\n",
            "     â†’ All 223 tracks are in \"AJFinds23\" (1233 tracks)\n",
            "     â†’ Keep: AJFinds23\n",
            "\n",
            "   â€¢ AJFindsHipHop24\n",
            "     â†’ All 146 tracks are in \"AJFinds24\" (434 tracks)\n",
            "     â†’ Keep: AJFinds24\n",
            "\n",
            "   â€¢ AJFindsOther21\n",
            "     â†’ All 810 tracks are in \"AJFinds21\" (1310 tracks)\n",
            "     â†’ Keep: AJFinds21\n",
            "\n",
            "   â€¢ AJFindsOther22\n",
            "     â†’ All 836 tracks are in \"AJFinds22\" (1150 tracks)\n",
            "     â†’ Keep: AJFinds22\n",
            "\n",
            "   â€¢ AJFindsOther23\n",
            "     â†’ All 943 tracks are in \"AJFinds23\" (1233 tracks)\n",
            "     â†’ Keep: AJFinds23\n",
            "\n",
            "   â€¢ AJFindsOther24\n",
            "     â†’ All 245 tracks are in \"AJFinds24\" (434 tracks)\n",
            "     â†’ Keep: AJFinds24\n",
            "\n",
            "   â€¢ DanceFindsApr25\n",
            "     â†’ All 19 tracks are in \"AJamElectronic\" (481 tracks)\n",
            "     â†’ Keep: AJamElectronic\n",
            "\n",
            "   â€¢ DanceFindsAug25\n",
            "     â†’ All 52 tracks are in \"AJamElectronic\" (481 tracks)\n",
            "     â†’ Keep: AJamElectronic\n",
            "\n",
            "   â€¢ DanceFindsDec25\n",
            "     â†’ All 28 tracks are in \"AJFindsDec25\" (88 tracks)\n",
            "     â†’ Keep: AJFindsDec25\n",
            "\n",
            "   â€¢ DanceFindsJul25\n",
            "     â†’ All 36 tracks are in \"AJamElectronic\" (481 tracks)\n",
            "     â†’ Keep: AJamElectronic\n",
            "\n",
            "   â€¢ DanceFindsJun25\n",
            "     â†’ All 18 tracks are in \"AJamElectronic\" (481 tracks)\n",
            "     â†’ Keep: AJamElectronic\n",
            "\n",
            "   â€¢ DanceFindsMar25\n",
            "     â†’ All 3 tracks are in \"AJamElectronic\" (481 tracks)\n",
            "     â†’ Keep: AJamElectronic\n",
            "\n",
            "   â€¢ DanceFindsMay25\n",
            "     â†’ All 20 tracks are in \"AJamElectronic\" (481 tracks)\n",
            "     â†’ Keep: AJamElectronic\n",
            "\n",
            "   â€¢ DanceFindsNov25\n",
            "     â†’ All 19 tracks are in \"AJamElectronic\" (481 tracks)\n",
            "     â†’ Keep: AJamElectronic\n",
            "\n",
            "   â€¢ DanceFindsOct25\n",
            "     â†’ All 1 tracks are in \"AJamElectronic\" (481 tracks)\n",
            "     â†’ Keep: AJamElectronic\n",
            "\n",
            "   â€¢ DanceFindsSep25\n",
            "     â†’ All 24 tracks are in \"AJamElectronic\" (481 tracks)\n",
            "     â†’ Keep: AJamElectronic\n",
            "\n",
            "   â€¢ HipHopFindsApr25\n",
            "     â†’ All 13 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsAug25\n",
            "     â†’ All 34 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsDec25\n",
            "     â†’ All 22 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsFeb25\n",
            "     â†’ All 10 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsJan25\n",
            "     â†’ All 4 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsJul25\n",
            "     â†’ All 19 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsJun25\n",
            "     â†’ All 30 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsMar25\n",
            "     â†’ All 6 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsMay25\n",
            "     â†’ All 13 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsNov25\n",
            "     â†’ All 9 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsOct25\n",
            "     â†’ All 17 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsSep25\n",
            "     â†’ All 13 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ Marchâ€™24\n",
            "     â†’ All 13 tracks are in \"SandTrap ğŸï¸ğŸ‡¹ğŸ‡­\" (982 tracks)\n",
            "     â†’ Keep: SandTrap ğŸï¸ğŸ‡¹ğŸ‡­\n",
            "\n",
            "   â€¢ OtherFindsApr25\n",
            "     â†’ All 40 tracks are in \"AJFindsApr25\" (72 tracks)\n",
            "     â†’ Keep: AJFindsApr25\n",
            "\n",
            "   â€¢ OtherFindsAug25\n",
            "     â†’ All 67 tracks are in \"AJFindsAug25\" (153 tracks)\n",
            "     â†’ Keep: AJFindsAug25\n",
            "\n",
            "   â€¢ OtherFindsDec25\n",
            "     â†’ All 38 tracks are in \"AJFindsDec25\" (88 tracks)\n",
            "     â†’ Keep: AJFindsDec25\n",
            "\n",
            "   â€¢ OtherFindsFeb25\n",
            "     â†’ All 3 tracks are in \"AJFindsFeb25\" (13 tracks)\n",
            "     â†’ Keep: AJFindsFeb25\n",
            "\n",
            "   â€¢ OtherFindsJan25\n",
            "     â†’ All 7 tracks are in \"AJFindsJan25\" (11 tracks)\n",
            "     â†’ Keep: AJFindsJan25\n",
            "\n",
            "   â€¢ OtherFindsJul25\n",
            "     â†’ All 35 tracks are in \"AJFindsJul25\" (90 tracks)\n",
            "     â†’ Keep: AJFindsJul25\n",
            "\n",
            "   â€¢ OtherFindsJun25\n",
            "     â†’ All 30 tracks are in \"AJFindsJun25\" (78 tracks)\n",
            "     â†’ Keep: AJFindsJun25\n",
            "\n",
            "   â€¢ OtherFindsMar25\n",
            "     â†’ All 14 tracks are in \"AJFindsMar25\" (23 tracks)\n",
            "     â†’ Keep: AJFindsMar25\n",
            "\n",
            "   â€¢ OtherFindsMay25\n",
            "     â†’ All 48 tracks are in \"AJFindsMay25\" (81 tracks)\n",
            "     â†’ Keep: AJFindsMay25\n",
            "\n",
            "   â€¢ OtherFindsNov25\n",
            "     â†’ All 200 tracks are in \"AJFindsNov25\" (228 tracks)\n",
            "     â†’ Keep: AJFindsNov25\n",
            "\n",
            "   â€¢ OtherFindsOct25\n",
            "     â†’ All 71 tracks are in \"AJFindsOct25\" (89 tracks)\n",
            "     â†’ Keep: AJFindsOct25\n",
            "\n",
            "   â€¢ OtherFindsSep25\n",
            "     â†’ All 32 tracks are in \"AJFindsSep25\" (69 tracks)\n",
            "     â†’ Keep: AJFindsSep25\n",
            "\n",
            "   â€¢ Pepper ğŸ«‘ \n",
            "     â†’ All 3 tracks are in \"AJFinds23\" (1233 tracks)\n",
            "     â†’ Keep: AJFinds23\n",
            "\n",
            "   â€¢ Trance \n",
            "     â†’ All 8 tracks are in \"Tekky \" (284 tracks)\n",
            "     â†’ Keep: Tekky \n",
            "\n",
            "   â€¢ Trapsoul\n",
            "     â†’ All 11 tracks are in \"Chill trap\" (517 tracks)\n",
            "     â†’ Keep: Chill trap\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ğŸ“Š SUMMARY\n",
            "================================================================================\n",
            "   Total playlists recommended for deletion/merge: 50\n",
            "   Playlists with zero track loss: 50\n",
            "   Total unique tracks that would need to be added: 0\n",
            "   Current total playlists: 195\n",
            "   After consolidation: 145 playlists\n",
            "   Reduction: 50 playlists (25.6%)\n"
          ]
        }
      ],
      "source": [
        "# Display comprehensive deletion/consolidation recommendations\n",
        "if consolidation_suggestions:\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ğŸ“‹ CONSOLIDATION RECOMMENDATIONS\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    df = pd.DataFrame(consolidation_suggestions)\n",
        "    df = df.sort_values(['tracks_lost', 'playlist_name'])\n",
        "    \n",
        "    # Separate by action type\n",
        "    delete_actions = df[df['action'] == 'delete']\n",
        "    merge_actions = df[df['action'] == 'merge']\n",
        "    \n",
        "    if len(delete_actions) > 0:\n",
        "        print(f\"\\nğŸ—‘ï¸  SAFE TO DELETE ({len(delete_actions)} playlists - 0 tracks lost):\")\n",
        "        print(\"-\" * 80)\n",
        "        for _, row in delete_actions.iterrows():\n",
        "            print(f\"   â€¢ {row['playlist_name']}\")\n",
        "            print(f\"     â†’ {row['reason']}\")\n",
        "            print(f\"     â†’ Keep: {row['alternative']}\")\n",
        "            print()\n",
        "    \n",
        "    if len(merge_actions) > 0:\n",
        "        print(f\"\\nğŸ”€ MERGE RECOMMENDATIONS ({len(merge_actions)} playlists):\")\n",
        "        print(\"-\" * 80)\n",
        "        for _, row in merge_actions.iterrows():\n",
        "            print(f\"   â€¢ {row['playlist_name']}\")\n",
        "            print(f\"     â†’ {row['reason']}\")\n",
        "            if row['tracks_lost'] > 0:\n",
        "                print(f\"     â†’ âš ï¸  {row['tracks_lost']} unique tracks would need to be added to {row['alternative']}\")\n",
        "            else:\n",
        "                print(f\"     â†’ âœ… No tracks lost - safe to merge\")\n",
        "            print()\n",
        "    \n",
        "    # Summary statistics\n",
        "    total_tracks_lost = df['tracks_lost'].sum()\n",
        "    zero_loss = len(df[df['tracks_lost'] == 0])\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ğŸ“Š SUMMARY\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"   Total playlists recommended for deletion/merge: {len(df)}\")\n",
        "    print(f\"   Playlists with zero track loss: {zero_loss}\")\n",
        "    print(f\"   Total unique tracks that would need to be added: {total_tracks_lost}\")\n",
        "    print(f\"   Current total playlists: {len(playlists)}\")\n",
        "    print(f\"   After consolidation: {len(playlists) - len(df)} playlists\")\n",
        "    print(f\"   Reduction: {len(df)} playlists ({100*len(df)/len(playlists):.1f}%)\")\n",
        "else:\n",
        "    print(\"\\nâœ… No consolidation recommendations - your library is well organized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7ï¸âƒ£ Detailed Track-Level Analysis\n",
        "\n",
        "For merge recommendations, let's see exactly which tracks would need to be added.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… All merge recommendations have zero track loss!\n"
          ]
        }
      ],
      "source": [
        "# For merge actions, show which tracks need to be added\n",
        "merge_details = []\n",
        "\n",
        "for suggestion in consolidation_suggestions:\n",
        "    if suggestion['action'] == 'merge' and suggestion['tracks_lost'] > 0:\n",
        "        delete_pid = suggestion['playlist_id']\n",
        "        delete_tracks = playlist_track_sets[delete_pid]\n",
        "        \n",
        "        # Find the playlist to merge into\n",
        "        keep_name = suggestion['alternative'].split('\"')[1] if '\"' in suggestion['alternative'] else suggestion['alternative']\n",
        "        keep_pid = None\n",
        "        for pid, info in playlist_info.items():\n",
        "            if info['name'] == keep_name:\n",
        "                keep_pid = pid\n",
        "                break\n",
        "        \n",
        "        if keep_pid:\n",
        "            keep_tracks = playlist_track_sets[keep_pid]\n",
        "            missing_tracks = delete_tracks - keep_tracks\n",
        "            \n",
        "            if missing_tracks:\n",
        "                # Get track names\n",
        "                missing_track_ids = list(missing_tracks)[:10]  # Show first 10\n",
        "                tracks_df = analyzer.tracks_all[analyzer.tracks_all['track_id'].isin(missing_track_ids)]\n",
        "                track_names = tracks_df[['name']].values.flatten().tolist() if len(tracks_df) > 0 else []\n",
        "                \n",
        "                merge_details.append({\n",
        "                    'Delete': suggestion['playlist_name'],\n",
        "                    'Merge Into': keep_name,\n",
        "                    'Missing Tracks': len(missing_tracks),\n",
        "                    'Sample Tracks': ', '.join(track_names[:5]) if track_names else 'N/A'\n",
        "                })\n",
        "\n",
        "if merge_details:\n",
        "    print(\"ğŸ“‹ Detailed Merge Analysis (tracks that need to be added):\")\n",
        "    print(\"=\" * 80)\n",
        "    df = pd.DataFrame(merge_details)\n",
        "    for _, row in df.iterrows():\n",
        "        print(f\"\\nğŸ—‘ï¸  Delete: {row['Delete']}\")\n",
        "        print(f\"   â†’ Merge into: {row['Merge Into']}\")\n",
        "        print(f\"   â†’ Add {row['Missing Tracks']} tracks\")\n",
        "        if row['Sample Tracks'] != 'N/A':\n",
        "            print(f\"   â†’ Sample: {row['Sample Tracks']}...\")\n",
        "else:\n",
        "    print(\"âœ… All merge recommendations have zero track loss!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8ï¸âƒ£ Reorganization Strategy\n",
        "\n",
        "Based on the analysis, here's a suggested reorganization of your library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "ğŸ“‹ REORGANIZATION PLAN\n",
            "================================================================================\n",
            "\n",
            "ğŸ—‘ï¸  DELETE (50 playlists):\n",
            "--------------------------------------------------------------------------------\n",
            "   â€¢ AJFindsOther24\n",
            "     â†’ All 245 tracks are in \"AJFinds24\" (434 tracks)\n",
            "     â†’ Keep: AJFinds24\n",
            "\n",
            "   â€¢ AJFindsDance24\n",
            "     â†’ All 43 tracks are in \"AJFinds24\" (434 tracks)\n",
            "     â†’ Keep: AJFinds24\n",
            "\n",
            "   â€¢ AJFindsHipHop24\n",
            "     â†’ All 146 tracks are in \"AJFinds24\" (434 tracks)\n",
            "     â†’ Keep: AJFinds24\n",
            "\n",
            "   â€¢ AJFindsOther23\n",
            "     â†’ All 943 tracks are in \"AJFinds23\" (1233 tracks)\n",
            "     â†’ Keep: AJFinds23\n",
            "\n",
            "   â€¢ AJFindsDance23\n",
            "     â†’ All 67 tracks are in \"AJFinds23\" (1233 tracks)\n",
            "     â†’ Keep: AJFinds23\n",
            "\n",
            "   â€¢ AJFindsHipHop23\n",
            "     â†’ All 223 tracks are in \"AJFinds23\" (1233 tracks)\n",
            "     â†’ Keep: AJFinds23\n",
            "\n",
            "   â€¢ AJFindsOther22\n",
            "     â†’ All 836 tracks are in \"AJFinds22\" (1150 tracks)\n",
            "     â†’ Keep: AJFinds22\n",
            "\n",
            "   â€¢ AJFindsDance22\n",
            "     â†’ All 96 tracks are in \"AJFinds22\" (1150 tracks)\n",
            "     â†’ Keep: AJFinds22\n",
            "\n",
            "   â€¢ AJFindsHipHop22\n",
            "     â†’ All 218 tracks are in \"AJFinds22\" (1150 tracks)\n",
            "     â†’ Keep: AJFinds22\n",
            "\n",
            "   â€¢ AJFindsOther21\n",
            "     â†’ All 810 tracks are in \"AJFinds21\" (1310 tracks)\n",
            "     â†’ Keep: AJFinds21\n",
            "\n",
            "   â€¢ AJFindsDance21\n",
            "     â†’ All 48 tracks are in \"AJFinds21\" (1310 tracks)\n",
            "     â†’ Keep: AJFinds21\n",
            "\n",
            "   â€¢ AJFindsHipHop21\n",
            "     â†’ All 452 tracks are in \"AJFinds21\" (1310 tracks)\n",
            "     â†’ Keep: AJFinds21\n",
            "\n",
            "   â€¢ Pepper ğŸ«‘ \n",
            "     â†’ All 3 tracks are in \"AJFinds23\" (1233 tracks)\n",
            "     â†’ Keep: AJFinds23\n",
            "\n",
            "   â€¢ DanceFindsNov25\n",
            "     â†’ All 19 tracks are in \"AJamElectronic\" (481 tracks)\n",
            "     â†’ Keep: AJamElectronic\n",
            "\n",
            "   â€¢ DanceFindsOct25\n",
            "     â†’ All 1 tracks are in \"AJamElectronic\" (481 tracks)\n",
            "     â†’ Keep: AJamElectronic\n",
            "\n",
            "   â€¢ DanceFindsSep25\n",
            "     â†’ All 24 tracks are in \"AJamElectronic\" (481 tracks)\n",
            "     â†’ Keep: AJamElectronic\n",
            "\n",
            "   â€¢ DanceFindsAug25\n",
            "     â†’ All 52 tracks are in \"AJamElectronic\" (481 tracks)\n",
            "     â†’ Keep: AJamElectronic\n",
            "\n",
            "   â€¢ DanceFindsJul25\n",
            "     â†’ All 36 tracks are in \"AJamElectronic\" (481 tracks)\n",
            "     â†’ Keep: AJamElectronic\n",
            "\n",
            "   â€¢ DanceFindsJun25\n",
            "     â†’ All 18 tracks are in \"AJamElectronic\" (481 tracks)\n",
            "     â†’ Keep: AJamElectronic\n",
            "\n",
            "   â€¢ DanceFindsMay25\n",
            "     â†’ All 20 tracks are in \"AJamElectronic\" (481 tracks)\n",
            "     â†’ Keep: AJamElectronic\n",
            "\n",
            "   â€¢ DanceFindsApr25\n",
            "     â†’ All 19 tracks are in \"AJamElectronic\" (481 tracks)\n",
            "     â†’ Keep: AJamElectronic\n",
            "\n",
            "   â€¢ DanceFindsMar25\n",
            "     â†’ All 3 tracks are in \"AJamElectronic\" (481 tracks)\n",
            "     â†’ Keep: AJamElectronic\n",
            "\n",
            "   â€¢ HipHopFindsNov25\n",
            "     â†’ All 9 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsOct25\n",
            "     â†’ All 17 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsSep25\n",
            "     â†’ All 13 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsAug25\n",
            "     â†’ All 34 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsJul25\n",
            "     â†’ All 19 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsJun25\n",
            "     â†’ All 30 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsMay25\n",
            "     â†’ All 13 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsApr25\n",
            "     â†’ All 13 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsMar25\n",
            "     â†’ All 6 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsFeb25\n",
            "     â†’ All 10 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsJan25\n",
            "     â†’ All 4 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ HipHopFindsDec25\n",
            "     â†’ All 22 tracks are in \"AJamHip-Hop\" (1557 tracks)\n",
            "     â†’ Keep: AJamHip-Hop\n",
            "\n",
            "   â€¢ OtherFindsNov25\n",
            "     â†’ All 200 tracks are in \"AJFindsNov25\" (228 tracks)\n",
            "     â†’ Keep: AJFindsNov25\n",
            "\n",
            "   â€¢ OtherFindsOct25\n",
            "     â†’ All 71 tracks are in \"AJFindsOct25\" (89 tracks)\n",
            "     â†’ Keep: AJFindsOct25\n",
            "\n",
            "   â€¢ OtherFindsSep25\n",
            "     â†’ All 32 tracks are in \"AJFindsSep25\" (69 tracks)\n",
            "     â†’ Keep: AJFindsSep25\n",
            "\n",
            "   â€¢ OtherFindsAug25\n",
            "     â†’ All 67 tracks are in \"AJFindsAug25\" (153 tracks)\n",
            "     â†’ Keep: AJFindsAug25\n",
            "\n",
            "   â€¢ OtherFindsJul25\n",
            "     â†’ All 35 tracks are in \"AJFindsJul25\" (90 tracks)\n",
            "     â†’ Keep: AJFindsJul25\n",
            "\n",
            "   â€¢ OtherFindsJun25\n",
            "     â†’ All 30 tracks are in \"AJFindsJun25\" (78 tracks)\n",
            "     â†’ Keep: AJFindsJun25\n",
            "\n",
            "   â€¢ OtherFindsMay25\n",
            "     â†’ All 48 tracks are in \"AJFindsMay25\" (81 tracks)\n",
            "     â†’ Keep: AJFindsMay25\n",
            "\n",
            "   â€¢ OtherFindsApr25\n",
            "     â†’ All 40 tracks are in \"AJFindsApr25\" (72 tracks)\n",
            "     â†’ Keep: AJFindsApr25\n",
            "\n",
            "   â€¢ OtherFindsMar25\n",
            "     â†’ All 14 tracks are in \"AJFindsMar25\" (23 tracks)\n",
            "     â†’ Keep: AJFindsMar25\n",
            "\n",
            "   â€¢ OtherFindsFeb25\n",
            "     â†’ All 3 tracks are in \"AJFindsFeb25\" (13 tracks)\n",
            "     â†’ Keep: AJFindsFeb25\n",
            "\n",
            "   â€¢ OtherFindsJan25\n",
            "     â†’ All 7 tracks are in \"AJFindsJan25\" (11 tracks)\n",
            "     â†’ Keep: AJFindsJan25\n",
            "\n",
            "   â€¢ OtherFindsDec25\n",
            "     â†’ All 38 tracks are in \"AJFindsDec25\" (88 tracks)\n",
            "     â†’ Keep: AJFindsDec25\n",
            "\n",
            "   â€¢ DanceFindsDec25\n",
            "     â†’ All 28 tracks are in \"AJFindsDec25\" (88 tracks)\n",
            "     â†’ Keep: AJFindsDec25\n",
            "\n",
            "   â€¢ Trapsoul\n",
            "     â†’ All 11 tracks are in \"Chill trap\" (517 tracks)\n",
            "     â†’ Keep: Chill trap\n",
            "\n",
            "   â€¢ Trance \n",
            "     â†’ All 8 tracks are in \"Tekky \" (284 tracks)\n",
            "     â†’ Keep: Tekky \n",
            "\n",
            "   â€¢ Marchâ€™24\n",
            "     â†’ All 13 tracks are in \"SandTrap ğŸï¸ğŸ‡¹ğŸ‡­\" (982 tracks)\n",
            "     â†’ Keep: SandTrap ğŸï¸ğŸ‡¹ğŸ‡­\n",
            "\n",
            "\n",
            "ğŸ”€ MERGE (0 playlists):\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "âœ… KEEP (143 playlists):\n",
            "--------------------------------------------------------------------------------\n",
            "   â€¢ AJamHip-Hop (1557 tracks)\n",
            "   â€¢ AJFinds21 (1310 tracks)\n",
            "   â€¢ AJFinds23 (1233 tracks)\n",
            "   â€¢ AJFinds22 (1150 tracks)\n",
            "   â€¢ SandTrap ğŸï¸ğŸ‡¹ğŸ‡­ (982 tracks)\n",
            "   â€¢ Sunhop â˜€ï¸ (797 tracks)\n",
            "   â€¢ HiğŸ€ (737 tracks)\n",
            "   â€¢ TrapNeverDies2.0ğŸ‘Š (722 tracks)\n",
            "   â€¢ TrapNeverDies (700 tracks)\n",
            "   â€¢ Ride ğŸš´â€â™‚ï¸ (603 tracks)\n",
            "   â€¢ AltHop (599 tracks)\n",
            "   â€¢ StylinğŸ¤™ (589 tracks)\n",
            "   â€¢ Echo (532 tracks)\n",
            "   â€¢ WatsUrFlvr?ğŸ¦ (525 tracks)\n",
            "   â€¢ Chill trap (517 tracks)\n",
            "   â€¢ AJamElectronic (481 tracks)\n",
            "   â€¢ AJamR&B/Soul (479 tracks)\n",
            "   â€¢ IcedLemonadeğŸ‹ (467 tracks)\n",
            "   â€¢ FunkRap (456 tracks)\n",
            "   â€¢ Moon ğŸŒ— (454 tracks)\n",
            "   ... and 123 more playlists\n",
            "\n",
            "================================================================================\n",
            "ğŸ“Š REORGANIZATION SUMMARY\n",
            "================================================================================\n",
            "   Current playlists: 195\n",
            "   Delete: 50\n",
            "   Merge: 0\n",
            "   Keep: 143\n",
            "   Final count: 143\n",
            "   Reduction: 50 playlists\n"
          ]
        }
      ],
      "source": [
        "# Build reorganization plan\n",
        "reorganization_plan = {\n",
        "    'delete': [],\n",
        "    'merge': [],\n",
        "    'keep': []\n",
        "}\n",
        "\n",
        "# Categorize all playlists\n",
        "all_playlist_ids = set(playlist_track_sets.keys())\n",
        "to_delete_ids = safe_to_delete\n",
        "to_keep_ids = all_playlist_ids - to_delete_ids\n",
        "\n",
        "# Build merge groups\n",
        "merge_groups = defaultdict(list)\n",
        "for suggestion in consolidation_suggestions:\n",
        "    if suggestion['action'] == 'merge':\n",
        "        keep_name = suggestion['alternative'].split('\"')[1] if '\"' in suggestion['alternative'] else suggestion['alternative']\n",
        "        merge_groups[keep_name].append(suggestion['playlist_name'])\n",
        "\n",
        "# Organize recommendations\n",
        "for suggestion in consolidation_suggestions:\n",
        "    if suggestion['action'] == 'delete':\n",
        "        reorganization_plan['delete'].append({\n",
        "            'name': suggestion['playlist_name'],\n",
        "            'reason': suggestion['reason'],\n",
        "            'alternative': suggestion['alternative']\n",
        "        })\n",
        "    elif suggestion['action'] == 'merge':\n",
        "        reorganization_plan['merge'].append({\n",
        "            'name': suggestion['playlist_name'],\n",
        "            'reason': suggestion['reason'],\n",
        "            'merge_into': suggestion['alternative'],\n",
        "            'tracks_to_add': suggestion['tracks_lost']\n",
        "        })\n",
        "\n",
        "# Keep all others\n",
        "for pid in to_keep_ids:\n",
        "    info = playlist_info[pid]\n",
        "    reorganization_plan['keep'].append({\n",
        "        'name': info['name'],\n",
        "        'track_count': info['track_count']\n",
        "    })\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"ğŸ“‹ REORGANIZATION PLAN\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\nğŸ—‘ï¸  DELETE ({len(reorganization_plan['delete'])} playlists):\")\n",
        "print(\"-\" * 80)\n",
        "for item in reorganization_plan['delete']:\n",
        "    print(f\"   â€¢ {item['name']}\")\n",
        "    print(f\"     â†’ {item['reason']}\")\n",
        "    print(f\"     â†’ Keep: {item['alternative']}\")\n",
        "    print()\n",
        "\n",
        "print(f\"\\nğŸ”€ MERGE ({len(reorganization_plan['merge'])} playlists):\")\n",
        "print(\"-\" * 80)\n",
        "for item in reorganization_plan['merge']:\n",
        "    print(f\"   â€¢ {item['name']}\")\n",
        "    print(f\"     â†’ {item['reason']}\")\n",
        "    if item['tracks_to_add'] > 0:\n",
        "        print(f\"     â†’ âš ï¸  Add {item['tracks_to_add']} tracks to: {item['merge_into']}\")\n",
        "    else:\n",
        "        print(f\"     â†’ âœ… {item['merge_into']}\")\n",
        "    print()\n",
        "\n",
        "print(f\"\\nâœ… KEEP ({len(reorganization_plan['keep'])} playlists):\")\n",
        "print(\"-\" * 80)\n",
        "# Sort by track count\n",
        "keep_sorted = sorted(reorganization_plan['keep'], key=lambda x: x['track_count'], reverse=True)\n",
        "for item in keep_sorted[:20]:  # Show top 20\n",
        "    print(f\"   â€¢ {item['name']} ({item['track_count']} tracks)\")\n",
        "if len(keep_sorted) > 20:\n",
        "    print(f\"   ... and {len(keep_sorted) - 20} more playlists\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ğŸ“Š REORGANIZATION SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"   Current playlists: {len(playlists)}\")\n",
        "print(f\"   Delete: {len(reorganization_plan['delete'])}\")\n",
        "print(f\"   Merge: {len(reorganization_plan['merge'])}\")\n",
        "print(f\"   Keep: {len(reorganization_plan['keep'])}\")\n",
        "print(f\"   Final count: {len(reorganization_plan['keep']) + len(merge_groups)}\")\n",
        "print(f\"   Reduction: {len(reorganization_plan['delete']) + len(reorganization_plan['merge'])} playlists\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Recommendations exported to: /Users/aryamaan/Desktop/Projects/spotim8/data/playlist_consolidation_recommendations.csv\n",
            "\n",
            "ğŸ“Š Summary:\n",
            "   Total recommendations: 50\n",
            "   Safe deletions (0 tracks lost): 50\n",
            "   Merge recommendations: 0\n",
            "\n",
            "ğŸ’¡ Next steps:\n",
            "   1. Review the CSV file: /Users/aryamaan/Desktop/Projects/spotim8/data/playlist_consolidation_recommendations.csv\n",
            "   2. Manually verify recommendations\n",
            "   3. Delete/merge playlists in Spotify\n",
            "   4. Re-run sync to update your library\n"
          ]
        }
      ],
      "source": [
        "# Export recommendations to CSV\n",
        "export_df = pd.DataFrame(consolidation_suggestions)\n",
        "\n",
        "# Add track counts using playlist_id\n",
        "export_df['track_count'] = export_df['playlist_id'].apply(\n",
        "    lambda pid: playlist_info.get(pid, {}).get('track_count', 0)\n",
        ")\n",
        "\n",
        "# Reorder columns\n",
        "export_df = export_df[['playlist_name', 'track_count', 'action', 'reason', 'tracks_lost', 'alternative']]\n",
        "\n",
        "# Save to CSV\n",
        "output_file = DATA_DIR / 'playlist_consolidation_recommendations.csv'\n",
        "export_df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"âœ… Recommendations exported to: {output_file}\")\n",
        "print(f\"\\nğŸ“Š Summary:\")\n",
        "print(f\"   Total recommendations: {len(export_df)}\")\n",
        "print(f\"   Safe deletions (0 tracks lost): {len(export_df[export_df['tracks_lost'] == 0])}\")\n",
        "print(f\"   Merge recommendations: {len(export_df[export_df['action'] == 'merge'])}\")\n",
        "print(f\"\\nğŸ’¡ Next steps:\")\n",
        "print(f\"   1. Review the CSV file: {output_file}\")\n",
        "print(f\"   2. Manually verify recommendations\")\n",
        "print(f\"   3. Delete/merge playlists in Spotify\")\n",
        "print(f\"   4. Re-run sync to update your library\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load streaming history if available\n",
        "from spotim8.streaming_history import load_streaming_history\n",
        "\n",
        "history_df = load_streaming_history(DATA_DIR)\n",
        "\n",
        "if history_df is not None and len(history_df) > 0:\n",
        "    print(\"=\"*80)\n",
        "    print(\"ğŸ“Š LISTENING-BASED REDUNDANCY ANALYSIS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Build track usage map (which tracks are actually played)\n",
        "    played_tracks = set()\n",
        "    if 'track_id' in history_df.columns:\n",
        "        played_tracks = set(history_df['track_id'].dropna().unique())\n",
        "    else:\n",
        "        # Match by artist + track name\n",
        "        played_track_names = set(zip(\n",
        "            history_df['artist_name'].str.lower().fillna(''),\n",
        "            history_df['track_name'].str.lower().fillna('')\n",
        "        ))\n",
        "        # Match with library tracks\n",
        "        # Load tracks and artists if not already loaded\n",
        "        if 'tracks' not in locals() or 'track_artists' not in locals() or 'artists' not in locals():\n",
        "            tracks = pd.read_parquet(DATA_DIR / \"tracks.parquet\")\n",
        "            track_artists = pd.read_parquet(DATA_DIR / \"track_artists.parquet\")\n",
        "            artists = pd.read_parquet(DATA_DIR / \"artists.parquet\")\n",
        "        \n",
        "        library_track_names = tracks.merge(\n",
        "            track_artists[track_artists['position'] == 0],\n",
        "            on='track_id'\n",
        "        ).merge(artists[['artist_id', 'name']], on='artist_id')\n",
        "        library_track_set = set(zip(\n",
        "            library_track_names['name_x'].str.lower().fillna(''),\n",
        "            library_track_names['name_y'].str.lower().fillna('')\n",
        "        ))\n",
        "        # Get track IDs for played tracks\n",
        "        matched = library_track_names[\n",
        "            library_track_names.apply(\n",
        "                lambda row: (row['name_x'].lower(), row['name_y'].lower()) in played_track_names,\n",
        "                axis=1\n",
        "            )\n",
        "        ]\n",
        "        played_tracks = set(matched['track_id'].unique())\n",
        "    \n",
        "    # Analyze playlist usage\n",
        "    print(\"\\nğŸ“Š Playlist Usage Analysis:\")\n",
        "    print(\"   (Playlists where tracks are actually played vs. just saved)\\n\")\n",
        "    \n",
        "    unused_playlists = []\n",
        "    low_usage_playlists = []\n",
        "    \n",
        "    for pid in playlist_track_sets.keys():\n",
        "        playlist_tracks_set = playlist_track_sets[pid]\n",
        "        if not playlist_tracks_set:\n",
        "            continue\n",
        "        \n",
        "        # Count how many tracks from this playlist were actually played\n",
        "        played_from_playlist = playlist_tracks_set & played_tracks\n",
        "        usage_rate = len(played_from_playlist) / len(playlist_tracks_set) if playlist_tracks_set else 0\n",
        "        \n",
        "        info = playlist_info[pid]\n",
        "        \n",
        "        if usage_rate == 0:\n",
        "            unused_playlists.append((pid, info['name'], len(playlist_tracks_set)))\n",
        "        elif usage_rate < 0.1:  # Less than 10% usage\n",
        "            low_usage_playlists.append((pid, info['name'], len(playlist_tracks_set), usage_rate * 100))\n",
        "    \n",
        "    if unused_playlists:\n",
        "        print(f\"ğŸ—‘ï¸  UNUSED PLAYLISTS ({len(unused_playlists)} playlists - 0% tracks played):\")\n",
        "        for pid, name, track_count in sorted(unused_playlists, key=lambda x: x[2], reverse=True)[:10]:\n",
        "            print(f\"   â€¢ {name} ({track_count} tracks) - Never played from\")\n",
        "        if len(unused_playlists) > 10:\n",
        "            print(f\"   ... and {len(unused_playlists) - 10} more\")\n",
        "    \n",
        "    if low_usage_playlists:\n",
        "        print(f\"\\nâš ï¸  LOW USAGE PLAYLISTS ({len(low_usage_playlists)} playlists - <10% tracks played):\")\n",
        "        for pid, name, track_count, usage_pct in sorted(low_usage_playlists, key=lambda x: x[3])[:10]:\n",
        "            print(f\"   â€¢ {name} ({track_count} tracks) - {usage_pct:.1f}% usage\")\n",
        "        if len(low_usage_playlists) > 10:\n",
        "            print(f\"   ... and {len(low_usage_playlists) - 10} more\")\n",
        "    \n",
        "    if not unused_playlists and not low_usage_playlists:\n",
        "        print(\"   âœ… All playlists have good usage rates!\")\n",
        "    \n",
        "    # Listening-weighted similarity\n",
        "    print(\"\\n\\nğŸ“Š Listening-Weighted Similarity Analysis:\")\n",
        "    print(\"   (Playlists with similar listening patterns, even if track overlap is low)\\n\")\n",
        "    \n",
        "    # Build listening frequency per track\n",
        "    track_listen_counts = {}\n",
        "    if 'track_id' in history_df.columns:\n",
        "        track_listen_counts = history_df.groupby('track_id').size().to_dict()\n",
        "    else:\n",
        "        # Count by artist + track name\n",
        "        track_name_counts = history_df.groupby(['artist_name', 'track_name']).size()\n",
        "        # Match to track IDs\n",
        "        for (artist, track), count in track_name_counts.items():\n",
        "            # Load tracks and artists if not already loaded\n",
        "            if 'tracks' not in locals() or 'track_artists' not in locals() or 'artists' not in locals():\n",
        "                tracks = pd.read_parquet(DATA_DIR / \"tracks.parquet\")\n",
        "                track_artists = pd.read_parquet(DATA_DIR / \"track_artists.parquet\")\n",
        "                artists = pd.read_parquet(DATA_DIR / \"artists.parquet\")\n",
        "            \n",
        "            matches = tracks.merge(\n",
        "                track_artists[track_artists['position'] == 0],\n",
        "                on='track_id'\n",
        "            ).merge(artists[['artist_id', 'name']], on='artist_id')\n",
        "            matches = matches[\n",
        "                (matches['name_x'].str.lower() == track.lower()) &\n",
        "                (matches['name_y'].str.lower() == artist.lower())\n",
        "            ]\n",
        "            if len(matches) > 0:\n",
        "                track_listen_counts[matches.iloc[0]['track_id']] = count\n",
        "    \n",
        "    # Calculate listening-weighted similarity\n",
        "    listening_redundant = []\n",
        "    for i, (pid1, set1) in enumerate(playlist_track_sets.items()):\n",
        "        if not set1:\n",
        "            continue\n",
        "        for j, (pid2, set2) in enumerate(playlist_track_sets.items()):\n",
        "            if i >= j or not set2:\n",
        "                continue\n",
        "            \n",
        "            # Get shared tracks\n",
        "            shared = set1 & set2\n",
        "            if not shared:\n",
        "                continue\n",
        "            \n",
        "            # Calculate listening-weighted similarity\n",
        "            shared_listens = sum(track_listen_counts.get(tid, 0) for tid in shared)\n",
        "            total_listens_1 = sum(track_listen_counts.get(tid, 0) for tid in set1)\n",
        "            total_listens_2 = sum(track_listen_counts.get(tid, 0) for tid in set2)\n",
        "            \n",
        "            if total_listens_1 == 0 or total_listens_2 == 0:\n",
        "                continue\n",
        "            \n",
        "            # Similarity based on shared listening frequency\n",
        "            listening_sim = shared_listens / max(total_listens_1, total_listens_2)\n",
        "            \n",
        "            # Also check traditional Jaccard\n",
        "            jaccard = jaccard_similarity(set1, set2)\n",
        "            \n",
        "            # If listening similarity is high but Jaccard is low, they serve similar purpose\n",
        "            if listening_sim > 0.5 and jaccard < 0.7:\n",
        "                info1 = playlist_info[pid1]\n",
        "                info2 = playlist_info[pid2]\n",
        "                listening_redundant.append((pid1, pid2, info1['name'], info2['name'], jaccard, listening_sim))\n",
        "    \n",
        "    if listening_redundant:\n",
        "        print(f\"ğŸ”— FUNCTIONALLY REDUNDANT PLAYLISTS ({len(listening_redundant)} pairs):\")\n",
        "        print(\"   (Different tracks but similar listening patterns)\\n\")\n",
        "        for pid1, pid2, name1, name2, jaccard, listening_sim in sorted(listening_redundant, key=lambda x: x[5], reverse=True)[:10]:\n",
        "            print(f\"   â€¢ {name1} â†” {name2}\")\n",
        "            print(f\"     Track overlap: {jaccard*100:.1f}%, Listening similarity: {listening_sim*100:.1f}%\")\n",
        "        if len(listening_redundant) > 10:\n",
        "            print(f\"   ... and {len(listening_redundant) - 10} more pairs\")\n",
        "    else:\n",
        "        print(\"   âœ… No functionally redundant playlists found based on listening patterns\")\n",
        "    \n",
        "    print(\"\\nğŸ’¡ Recommendations:\")\n",
        "    print(\"   â€¢ Consider deleting unused playlists (0% usage)\")\n",
        "    print(\"   â€¢ Review low usage playlists - they may be outdated\")\n",
        "    print(\"   â€¢ Functionally redundant playlists might be merged even with low track overlap\")\n",
        "else:\n",
        "    print(\"âš ï¸  No streaming history data available\")\n",
        "    print(\"   Run the streaming history sync in 04_analyze_listening_history.ipynb to enable this analysis\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Done!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Done!\n",
        "\n",
        "**Summary:**\n",
        "- âœ… Identified redundant playlists using multiple similarity metrics\n",
        "- âœ… Found playlists safe to delete (zero track loss)\n",
        "- âœ… Suggested merge strategies for high-overlap playlists\n",
        "- âœ… Created reorganization plan\n",
        "- âœ… Exported recommendations to CSV\n",
        "\n",
        "**Next Steps:**\n",
        "1. Review the recommendations in the CSV file\n",
        "2. Manually verify each suggestion\n",
        "3. Delete/merge playlists in Spotify\n",
        "4. Re-run `01_sync_data.ipynb` to update your library\n",
        "5. Re-run this notebook to verify cleanup\n",
        "\n",
        "**Workflow:**\n",
        "- `01_sync_data.ipynb` â†’ `02_analyze_library.ipynb` â†’ `03_playlist_analysis.ipynb` â†’ `04_analyze_listening_history.ipynb` â†’ `05_liked_songs_monthly_playlists.ipynb` â†’ `06_identify_redundant_playlists.ipynb`\n",
        "\n",
        "**Note:** Always verify recommendations manually before deleting playlists!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
