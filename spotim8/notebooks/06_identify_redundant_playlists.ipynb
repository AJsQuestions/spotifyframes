{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ—‘ï¸ Identify Redundant Playlists & Aggressive Reorganization\n",
    "\n",
    "Analyze your **user-created playlists** to identify **redundant playlists** with **AGGRESSIVE thresholds** to maximize consolidation without losing information.\n",
    "\n",
    "**What this notebook does (AGGRESSIVE MODE):**\n",
    "- ğŸ” Finds playlists with high track overlap (>50% similarity - lowered thresholds)\n",
    "- ğŸ“Š Identifies playlists that are subsets of other playlists\n",
    "- ğŸ¯ Suggests playlists safe to delete (zero track loss)\n",
    "- ğŸ“‹ Proposes aggressive reorganization strategies\n",
    "- ğŸ’¡ Recommends consolidation merges (add missing tracks, zero loss after merge)\n",
    "- ğŸ“¦ Identifies groups of small playlists that can merge into larger ones\n",
    "- ğŸ”€ **FORCES suggestions** for maximum playlist reduction without information loss\n",
    "- âœ… **EXCLUDES auto-generated \"AJ\" playlists** - these are managed by the sync script\n",
    "\n",
    "**Key Changes (Aggressive Mode):**\n",
    "- **Auto-generated exclusion**: All playlists starting with \"AJ\" prefix are excluded from analysis\n",
    "- Lowered similarity thresholds: >70% (was >90%) for high overlap, >50% (was >80%) for near-duplicates\n",
    "- Size-based merge candidates: Small playlists (3x+ smaller) with >50% overlap â†’ merge into larger\n",
    "- Group consolidations: Multiple small playlists can merge into a single larger playlist\n",
    "- **Consolidation strategies**: New strategies for similar playlists (40-50% similarity) with merge/combine/review recommendations\n",
    "- **Zero information loss**: All suggestions preserve all tracks via merge operations\n",
    "\n",
    "**Prerequisites:** \n",
    "- Run `01_sync_data.ipynb` to download your library\n",
    "- Run `04_analyze_listening_history.ipynb` (optional) to enable listening-based redundancy detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "âœ… Project root: /Users/aryamaan/Desktop/Projects/SPOTIM8\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "%pip install -q pandas pyarrow tqdm\n",
    "\n",
    "# Setup project - this adds project root to path\n",
    "from pathlib import Path\n",
    "from notebook_helpers import setup_project\n",
    "\n",
    "PROJECT_ROOT = setup_project(Path(\"../..\").resolve())\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Data directory: /Users/aryamaan/Desktop/Projects/SPOTIM8/data\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, List, Set, Tuple\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from spotim8.analysis import LibraryAnalyzer, PlaylistSimilarityEngine\n",
    "\n",
    "# Data directory\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "print(f\"ğŸ“ Data directory: {DATA_DIR.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Load Library Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 560 playlists, 5,548 tracks\n",
      "ğŸ” Analyzing 64 playlists...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64e8c4b5960418d94ff2d63988d1e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Comparing playlists:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Redundancy analysis complete!\n",
      "   Found 0 exact duplicates\n",
      "   Found 0 subset relationships\n",
      "   Found 0 high overlap pairs\n",
      "   Found 2 near-duplicate pairs\n",
      "   Found 149 merge candidates\n",
      "   Found 28 similar playlist pairs\n"
     ]
    }
   ],
   "source": [
    "# Identify redundant playlists using helper functions\n",
    "from notebook_helpers import identify_redundant_playlists\n",
    "\n",
    "# This function handles all the logic: loading data, filtering auto-generated playlists,\n",
    "# building track sets, and analyzing redundancy\n",
    "redundancy_results = identify_redundant_playlists(DATA_DIR, exclude_auto_generated=True)\n",
    "\n",
    "# Extract results for use in subsequent cells\n",
    "playlist_track_sets = redundancy_results['playlist_track_sets']\n",
    "playlist_info = redundancy_results['playlist_info']\n",
    "exact_duplicates = redundancy_results['exact_duplicates']\n",
    "subsets = redundancy_results['subsets']\n",
    "high_overlap = redundancy_results['high_overlap']\n",
    "near_duplicates = redundancy_results['near_duplicates']\n",
    "merge_candidates = redundancy_results['merge_candidates']\n",
    "similar_playlists = redundancy_results['similar_playlists']\n",
    "excluded_count = redundancy_results['excluded_count']\n",
    "\n",
    "print(f\"\\nâœ… Redundancy analysis complete!\")\n",
    "print(f\"   Found {len(exact_duplicates)} exact duplicates\")\n",
    "print(f\"   Found {len(subsets)} subset relationships\")\n",
    "print(f\"   Found {len(high_overlap)} high overlap pairs\")\n",
    "print(f\"   Found {len(near_duplicates)} near-duplicate pairs\")\n",
    "print(f\"   Found {len(merge_candidates)} merge candidates\")\n",
    "print(f\"   Found {len(similar_playlists)} similar playlist pairs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Redundancy Analysis Results\n",
    "\n",
    "The redundancy analysis has been completed using helper functions. Results are available below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Track sets built for 64 user-created playlists\n",
      "   (Excluded 46 auto-generated 'AJ' playlists)\n",
      "ğŸ“Š Total unique tracks across all analyzed playlists: 3,804\n",
      "\n",
      "ğŸ“‹ Sample playlist info (first 5):\n",
      "   1. OtherFinds25: 281 tracks\n",
      "   2. Jan26: 92 tracks\n",
      "   3. Trapsoul: 57 tracks\n",
      "   4. DarkThots (ALLdTIME): 48 tracks\n",
      "   5. Pop ig dont deep it: 225 tracks\n"
     ]
    }
   ],
   "source": [
    "# Track sets and playlist info are already built by identify_redundant_playlists()\n",
    "# Display summary\n",
    "print(f\"âœ… Track sets built for {len(playlist_track_sets)} user-created playlists\")\n",
    "print(f\"   (Excluded {excluded_count} auto-generated 'AJ' playlists)\")\n",
    "print(f\"ğŸ“Š Total unique tracks across all analyzed playlists: {len(set().union(*playlist_track_sets.values())):,}\")\n",
    "\n",
    "# Display sample playlist info\n",
    "print(f\"\\nğŸ“‹ Sample playlist info (first 5):\")\n",
    "for i, (pid, info) in enumerate(list(playlist_info.items())[:5]):\n",
    "    print(f\"   {i+1}. {info['name']}: {info['track_count']} tracks\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Find Redundant Playlists\n",
    "\n",
    "We'll identify redundancy using multiple criteria with **aggressive thresholds** to maximize consolidation without loss:\n",
    "1. **Exact duplicates** - Same tracks\n",
    "2. **Subsets** - All tracks in one playlist are in another\n",
    "3. **High overlap** - Very similar track sets (>70% overlap - lowered from 90%)\n",
    "4. **Near-duplicates** - High similarity with moderate differences (>50% overlap)\n",
    "5. **Consolidation candidates** - Playlists that can be merged into larger playlists\n",
    "6. **Group merges** - Multiple small playlists that can be merged together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ“Š REDUNDANCY ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "âœ… Analysis complete!\n",
      "   Exact duplicates: 0\n",
      "   Subsets: 0\n",
      "   High overlap (>70%): 0\n",
      "   Near duplicates (50-70%): 2\n",
      "   Merge candidates (size-based): 149\n",
      "   Similar playlists (40-50%): 28\n",
      "\n",
      "   Total user-created playlists analyzed: 64\n",
      "   Auto-generated 'AJ' playlists excluded: 46\n"
     ]
    }
   ],
   "source": [
    "# Analysis is already complete from identify_redundant_playlists() in Cell 5\n",
    "# Results are available in the variables extracted from redundancy_results\n",
    "# This cell provides summary statistics\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ“Š REDUNDANCY ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nâœ… Analysis complete!\")\n",
    "print(f\"   Exact duplicates: {len(exact_duplicates)}\")\n",
    "print(f\"   Subsets: {len(subsets)}\")\n",
    "print(f\"   High overlap (>70%): {len(high_overlap)}\")\n",
    "print(f\"   Near duplicates (50-70%): {len(near_duplicates)}\")\n",
    "print(f\"   Merge candidates (size-based): {len(merge_candidates)}\")\n",
    "print(f\"   Similar playlists (40-50%): {len(similar_playlists)}\")\n",
    "print(f\"\\n   Total user-created playlists analyzed: {len(playlist_info)}\")\n",
    "print(f\"   Auto-generated 'AJ' playlists excluded: {excluded_count}\")\n",
    "\n",
    "# Note: The actual analysis was performed by identify_redundant_playlists() helper function\n",
    "# All similarity calculations and comparisons are handled by the helper module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… No exact duplicates found\n"
     ]
    }
   ],
   "source": [
    "# Display exact duplicates\n",
    "if exact_duplicates:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ”„ EXACT DUPLICATES (Same tracks, can delete one)\")\n",
    "    print(\"=\" * 80)\n",
    "    for pid1, pid2 in exact_duplicates:\n",
    "        info1 = playlist_info[pid1]\n",
    "        info2 = playlist_info[pid2]\n",
    "        print(f\"\\nğŸ“‹ {info1['name']} ({info1['track_count']} tracks)\")\n",
    "        print(f\"   âš¡ Duplicate of: {info2['name']} ({info2['track_count']} tracks)\")\n",
    "        print(f\"   ğŸ’¡ Recommendation: Delete one (keep the one with better name)\")\n",
    "else:\n",
    "    print(\"âœ… No exact duplicates found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… No subset playlists found\n"
     ]
    }
   ],
   "source": [
    "# Display subsets (playlists fully contained in others)\n",
    "if subsets:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“¦ SUBSETS (Fully contained in another playlist - SAFE TO DELETE)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    subset_df = []\n",
    "    for subset_pid, superset_pid, subset_size, superset_size in subsets:\n",
    "        subset_info = playlist_info[subset_pid]\n",
    "        superset_info = playlist_info[superset_pid]\n",
    "        subset_df.append({\n",
    "            'Subset Playlist': subset_info['name'],\n",
    "            'Subset Tracks': subset_size,\n",
    "            'Contained In': superset_info['name'],\n",
    "            'Superset Tracks': superset_size,\n",
    "            'Coverage': f\"{subset_size}/{superset_size} ({100*subset_size/superset_size:.1f}%)\"\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(subset_df)\n",
    "    df = df.sort_values('Subset Tracks', ascending=False)\n",
    "    print(f\"\\nğŸ“Š Found {len(df)} playlists that are subsets of others:\\n\")\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Identify unique subset playlists (safe to delete)\n",
    "    safe_to_delete = set([subset_pid for subset_pid, _, _, _ in subsets])\n",
    "    print(f\"\\nâœ… {len(safe_to_delete)} playlists can be safely deleted (all tracks are in other playlists)\")\n",
    "else:\n",
    "    print(\"\\nâœ… No subset playlists found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… No high-overlap playlists found\n"
     ]
    }
   ],
   "source": [
    "# Display high overlap playlists\n",
    "if high_overlap:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ¯ HIGH OVERLAP (>70% similarity - Strong merge candidates)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    overlap_df = []\n",
    "    for pid1, pid2, jaccard, overlap1, overlap2 in high_overlap:\n",
    "        info1 = playlist_info[pid1]\n",
    "        info2 = playlist_info[pid2]\n",
    "        missing1 = len(playlist_track_sets[pid1] - playlist_track_sets[pid2])\n",
    "        missing2 = len(playlist_track_sets[pid2] - playlist_track_sets[pid1])\n",
    "        overlap_df.append({\n",
    "            'Playlist 1': info1['name'],\n",
    "            'Tracks 1': info1['track_count'],\n",
    "            'Playlist 2': info2['name'],\n",
    "            'Tracks 2': info2['track_count'],\n",
    "            'Similarity': f\"{jaccard*100:.1f}%\",\n",
    "            'P1â†’P2 Missing': missing1,\n",
    "            'P2â†’P1 Missing': missing2,\n",
    "            'P1 in P2': f\"{overlap1*100:.1f}%\",\n",
    "            'P2 in P1': f\"{overlap2*100:.1f}%\",\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(overlap_df)\n",
    "    df = df.sort_values('Similarity', ascending=False)\n",
    "    print(f\"\\nğŸ“Š Found {len(df)} playlist pairs with >70% similarity:\\n\")\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nğŸ’¡ Aggressive Recommendations:\")\n",
    "    print(\"   - MERGE: If one playlist is smaller, merge it into the larger one\")\n",
    "    print(\"   - CONSOLIDATE: Add missing tracks from smaller to larger playlist\")\n",
    "    print(\"   - DELETE: After merging, delete the smaller playlist (no track loss)\")\n",
    "else:\n",
    "    print(\"\\nâœ… No high-overlap playlists found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ”— NEAR-DUPLICATES (50-70% similarity - Consolidation candidates)\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Top 2 near-duplicate pairs (showing first 30):\n",
      "\n",
      "    Playlist 1  Tracks 1       Playlist 2  Tracks 2 Similarity  P1â†’P2 Missing  P2â†’P1 Missing P1 in P2 P2 in P1\n",
      "ChillSunHop V2       882 TrapNeverDies3.0      1140      53.6%            176            434    80.0%    61.9%\n",
      " IcedLemonadeğŸ‹       503      RvRChrls3 ğŸ¦¦       561      52.7%            136            194    73.0%    65.4%\n",
      "\n",
      "ğŸ’¡ Aggressive Consolidation Recommendations:\n",
      "   - MERGE: If playlists serve similar purpose, merge by adding missing tracks\n",
      "   - CONSOLIDATE: Merge smaller into larger if overlap >50% and size difference >2x\n",
      "   - DELETE: After merging, delete merged playlist (zero track loss)\n",
      "\n",
      "================================================================================\n",
      "ğŸ“¦ MERGE CANDIDATES (Small playlists that can merge into larger ones)\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Top 30 merge candidates (showing first 30):\n",
      "\n",
      "      Small Playlist  Small Tracks   Large Playlist  Large Tracks Overlap  Tracks to Add Size Ratio\n",
      "            Trapsoul            57   ChillSunHop V2           882   91.2%              5      15.5x\n",
      "            Trapsoul            57          StylinğŸ¤™           634   86.0%              8      11.1x\n",
      "            Trapsoul            57          AltHop3           936   86.0%              8      16.4x\n",
      "            Trapsoul            57   WatsUrFlvr? V3           616   86.0%              8      10.8x\n",
      "            Trapsoul            57       InMyRoom ğŸ’½           366   84.2%              9       6.4x\n",
      "            Trapsoul            57      Ride the ğŸŒŠ            283   84.2%              9       5.0x\n",
      "            Trapsoul            57            GLyD3           515   84.2%              9       9.0x\n",
      "            Trapsoul            57              HiğŸ€           765   82.5%             10      13.4x\n",
      "            Trapsoul            57        Ride ğŸš´â€â™‚ï¸           651   82.5%             10      11.4x\n",
      "            Trapsoul            57     2Silk2Velvet           524   75.4%             14       9.2x\n",
      "            Trapsoul            57           Jams ğŸ“           491   75.4%             14       8.6x\n",
      "            Trapsoul            57    IcedLemonadeğŸ‹           503   73.7%             15       8.8x\n",
      "            Trapsoul            57      RvRChrls3 ğŸ¦¦           561   73.7%             15       9.8x\n",
      "            Trapsoul            57 TrapNeverDies3.0          1140   71.9%             16      20.0x\n",
      "            Trapsoul            57       OnDStreetğŸš¦           496   70.2%             17       8.7x\n",
      "DarkThots (ALLdTIME)            48           Jams ğŸ“           491   58.3%             20      10.2x\n",
      "            Trapsoul            57             WUT4           507   61.4%             22       8.9x\n",
      "DarkThots (ALLdTIME)            48   ChillSunHop V2           882   52.1%             23      18.4x\n",
      "            Trapsoul            57   SummerChill ğŸŒğŸ¥¶           458   59.6%             23       8.0x\n",
      "            Trapsoul            57         Flwrs4UğŸŒ¸           397   57.9%             24       7.0x\n",
      "               Jan26            92          StylinğŸ¤™           634   73.9%             24       6.9x\n",
      "               Jan26            92        Ride ğŸš´â€â™‚ï¸           651   73.9%             24       7.1x\n",
      "            Trapsoul            57            Echo3           724   54.4%             26      12.7x\n",
      "               Jan26            92           Jams ğŸ“           491   71.7%             26       5.3x\n",
      "               Jan26            92       InMyRoom ğŸ’½           366   71.7%             26       4.0x\n",
      "            Trapsoul            57    SandTrap ğŸï¸ğŸ‡¹ğŸ‡­           986   50.9%             28      17.3x\n",
      "               Jan26            92   WatsUrFlvr? V3           616   62.0%             35       6.7x\n",
      "               Jan26            92              HiğŸ€           765   60.9%             36       8.3x\n",
      "               Jan26            92           DunceğŸª©           403   57.6%             39       4.4x\n",
      "               Jan26            92            GLyD3           515   57.6%             39       5.6x\n",
      "\n",
      "   ... and 119 more candidates\n",
      "\n",
      "ğŸ’¡ Aggressive Recommendations:\n",
      "   - MERGE: Add missing tracks from small playlist to large playlist\n",
      "   - DELETE: After merging, delete the small playlist (zero track loss)\n",
      "   - CONSOLIDATE: Reduces playlist count without losing any tracks\n"
     ]
    }
   ],
   "source": [
    "# Display near-duplicates\n",
    "if near_duplicates:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ”— NEAR-DUPLICATES (50-70% similarity - Consolidation candidates)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    near_df = []\n",
    "    for pid1, pid2, jaccard, overlap1, overlap2 in near_duplicates[:30]:  # Show top 30\n",
    "        info1 = playlist_info[pid1]\n",
    "        info2 = playlist_info[pid2]\n",
    "        missing1 = len(playlist_track_sets[pid1] - playlist_track_sets[pid2])\n",
    "        missing2 = len(playlist_track_sets[pid2] - playlist_track_sets[pid1])\n",
    "        near_df.append({\n",
    "            'Playlist 1': info1['name'],\n",
    "            'Tracks 1': info1['track_count'],\n",
    "            'Playlist 2': info2['name'],\n",
    "            'Tracks 2': info2['track_count'],\n",
    "            'Similarity': f\"{jaccard*100:.1f}%\",\n",
    "            'P1â†’P2 Missing': missing1,\n",
    "            'P2â†’P1 Missing': missing2,\n",
    "            'P1 in P2': f\"{overlap1*100:.1f}%\",\n",
    "            'P2 in P1': f\"{overlap2*100:.1f}%\",\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(near_df)\n",
    "    df = df.sort_values('Similarity', ascending=False)\n",
    "    print(f\"\\nğŸ“Š Top {len(df)} near-duplicate pairs (showing first 30):\\n\")\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    if len(near_duplicates) > 30:\n",
    "        print(f\"\\n   ... and {len(near_duplicates) - 30} more pairs\")\n",
    "    \n",
    "    print(\"\\nğŸ’¡ Aggressive Consolidation Recommendations:\")\n",
    "    print(\"   - MERGE: If playlists serve similar purpose, merge by adding missing tracks\")\n",
    "    print(\"   - CONSOLIDATE: Merge smaller into larger if overlap >50% and size difference >2x\")\n",
    "    print(\"   - DELETE: After merging, delete merged playlist (zero track loss)\")\n",
    "else:\n",
    "    print(\"\\nâœ… No near-duplicate playlists found\")\n",
    "\n",
    "# Display merge candidates (size-based)\n",
    "if merge_candidates:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“¦ MERGE CANDIDATES (Small playlists that can merge into larger ones)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    merge_df = []\n",
    "    for small_pid, large_pid, small_overlap, large_overlap, small_size, large_size in merge_candidates[:30]:\n",
    "        small_info = playlist_info[small_pid]\n",
    "        large_info = playlist_info[large_pid]\n",
    "        missing_tracks = len(playlist_track_sets[small_pid] - playlist_track_sets[large_pid])\n",
    "        merge_df.append({\n",
    "            'Small Playlist': small_info['name'],\n",
    "            'Small Tracks': small_size,\n",
    "            'Large Playlist': large_info['name'],\n",
    "            'Large Tracks': large_size,\n",
    "            'Overlap': f\"{small_overlap*100:.1f}%\",\n",
    "            'Tracks to Add': missing_tracks,\n",
    "            'Size Ratio': f\"{large_size/small_size:.1f}x\"\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(merge_df)\n",
    "    df = df.sort_values('Tracks to Add')\n",
    "    print(f\"\\nğŸ“Š Top {len(df)} merge candidates (showing first 30):\\n\")\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    if len(merge_candidates) > 30:\n",
    "        print(f\"\\n   ... and {len(merge_candidates) - 30} more candidates\")\n",
    "    \n",
    "    print(\"\\nğŸ’¡ Aggressive Recommendations:\")\n",
    "    print(\"   - MERGE: Add missing tracks from small playlist to large playlist\")\n",
    "    print(\"   - DELETE: After merging, delete the small playlist (zero track loss)\")\n",
    "    print(\"   - CONSOLIDATE: Reduces playlist count without losing any tracks\")\n",
    "else:\n",
    "    print(\"\\nâœ… No size-based merge candidates found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Comprehensive Redundancy Analysis\n",
    "\n",
    "Now let's identify ALL user-created playlists that can be safely deleted or consolidated.\n",
    "\n",
    "**NOTE:** Auto-generated playlists starting with \"AJ\" prefix are excluded from analysis - they're managed by the sync script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Built consolidation suggestions!\n",
      "   Safe to delete: 23 playlists\n",
      "   Total suggestions: 23\n"
     ]
    }
   ],
   "source": [
    "# Build comprehensive consolidation suggestions using helper functions\n",
    "from notebook_helpers import build_consolidation_suggestions, is_auto_generated_playlist\n",
    "\n",
    "# Use helper function to build consolidation suggestions (excludes auto-generated playlists)\n",
    "consolidation_results = build_consolidation_suggestions(redundancy_results, exclude_auto_generated=True)\n",
    "\n",
    "# Extract results\n",
    "safe_to_delete = consolidation_results['safe_to_delete']\n",
    "consolidation_suggestions = consolidation_results['consolidation_suggestions']\n",
    "\n",
    "print(f\"âœ… Built consolidation suggestions!\")\n",
    "print(f\"   Safe to delete: {len(safe_to_delete)} playlists\")\n",
    "print(f\"   Total suggestions: {len(consolidation_suggestions)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“‹ CONSOLIDATION RECOMMENDATIONS (AGGRESSIVE - Zero Track Loss)\n",
      "================================================================================\n",
      "\n",
      "ğŸ”€ MERGE RECOMMENDATIONS (23 playlists - Zero track loss after adding missing tracks):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "   ğŸ”„ Consolidation merges (add missing tracks - 23 playlists):\n",
      "      â€¢ JazzyğŸ·\n",
      "        â†’ Small playlist (19 tracks) with 73.7% overlap in larger \"IcedLemonadeğŸ‹\" (503 tracks)\n",
      "        â†’ Add 5 tracks: Merge into \"IcedLemonadeğŸ‹\" (add 5 missing tracks, zero loss)\n",
      "      â€¢ Loungin\n",
      "        â†’ Small playlist (11 tracks) with 54.5% overlap in larger \"Pop ig dont deep it\" (225 tracks)\n",
      "        â†’ Add 5 tracks: Merge into \"Pop ig dont deep it\" (add 5 missing tracks, zero loss)\n",
      "      â€¢  STFU\n",
      "        â†’ Small playlist (24 tracks) with 66.7% overlap in larger \"SandTrap ğŸï¸ğŸ‡¹ğŸ‡­\" (986 tracks)\n",
      "        â†’ Add 8 tracks: Merge into \"SandTrap ğŸï¸ğŸ‡¹ğŸ‡­\" (add 8 missing tracks, zero loss)\n",
      "      â€¢ Trapsoul\n",
      "        â†’ Small playlist (57 tracks) with 84.2% overlap in larger \"InMyRoom ğŸ’½\" (366 tracks)\n",
      "        â†’ Add 9 tracks: Merge into \"InMyRoom ğŸ’½\" (add 9 missing tracks, zero loss)\n",
      "      â€¢ Joooonâ˜€ï¸\n",
      "        â†’ Small playlist (30 tracks) with 53.3% overlap in larger \"OnDStreetğŸš¦\" (496 tracks)\n",
      "        â†’ Add 14 tracks: Merge into \"OnDStreetğŸš¦\" (add 14 missing tracks, zero loss)\n",
      "      â€¢ OldSoulğŸ“»\n",
      "        â†’ Small playlist (32 tracks) with 56.2% overlap in larger \"Musi(c)ngs\" (234 tracks)\n",
      "        â†’ Add 14 tracks: Merge into \"Musi(c)ngs\" (add 14 missing tracks, zero loss)\n",
      "      â€¢ DarkThots (ALLdTIME)\n",
      "        â†’ Small playlist (48 tracks) with 58.3% overlap in larger \"Jams ğŸ“\" (491 tracks)\n",
      "        â†’ Add 20 tracks: Merge into \"Jams ğŸ“\" (add 20 missing tracks, zero loss)\n",
      "      â€¢ Sneeeeeek ğŸ‘Ÿ\n",
      "        â†’ Small playlist (106 tracks) with 77.4% overlap in larger \"ChillSunHop V2\" (882 tracks)\n",
      "        â†’ Add 24 tracks: Merge into \"ChillSunHop V2\" (add 24 missing tracks, zero loss)\n",
      "      â€¢ Flo\n",
      "        â†’ Small playlist (100 tracks) with 75.0% overlap in larger \"InMyRoom ğŸ’½\" (366 tracks)\n",
      "        â†’ Add 25 tracks: Merge into \"InMyRoom ğŸ’½\" (add 25 missing tracks, zero loss)\n",
      "      â€¢ Jan26\n",
      "        â†’ Small playlist (92 tracks) with 71.7% overlap in larger \"InMyRoom ğŸ’½\" (366 tracks)\n",
      "        â†’ Add 26 tracks: Merge into \"InMyRoom ğŸ’½\" (add 26 missing tracks, zero loss)\n",
      "      â€¢ Bnce\n",
      "        â†’ Small playlist (62 tracks) with 56.5% overlap in larger \"Jams ğŸ“\" (491 tracks)\n",
      "        â†’ Add 27 tracks: Merge into \"Jams ğŸ“\" (add 27 missing tracks, zero loss)\n",
      "      â€¢ GrimeCrime\n",
      "        â†’ Small playlist (127 tracks) with 67.7% overlap in larger \"ChillSunHop V2\" (882 tracks)\n",
      "        â†’ Add 41 tracks: Merge into \"ChillSunHop V2\" (add 41 missing tracks, zero loss)\n",
      "      â€¢ SadBoi2\n",
      "        â†’ Small playlist (170 tracks) with 75.3% overlap in larger \"WatsUrFlvr? V3\" (616 tracks)\n",
      "        â†’ Add 42 tracks: Merge into \"WatsUrFlvr? V3\" (add 42 missing tracks, zero loss)\n",
      "      â€¢ Four 2060 Nine V2\n",
      "        â†’ Small playlist (104 tracks) with 54.8% overlap in larger \"HiğŸ€\" (765 tracks)\n",
      "        â†’ Add 47 tracks: Merge into \"HiğŸ€\" (add 47 missing tracks, zero loss)\n",
      "      â€¢ hrDnc ğŸš¨\n",
      "        â†’ Small playlist (99 tracks) with 50.5% overlap in larger \"Jams ğŸ“\" (491 tracks)\n",
      "        â†’ Add 49 tracks: Merge into \"Jams ğŸ“\" (add 49 missing tracks, zero loss)\n",
      "      ... and 8 more consolidation merges\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š AGGRESSIVE CONSOLIDATION SUMMARY\n",
      "================================================================================\n",
      "   Total playlists recommended for deletion/merge: 23\n",
      "   Perfect merges (0 tracks to add): 0\n",
      "   Consolidation merges (add missing tracks): 23\n",
      "   Total unique tracks to add (zero loss after merge): 968\n",
      "   Current total playlists: 64\n",
      "   After consolidation: 41 playlists\n",
      "   Reduction: 23 playlists (35.9%)\n",
      "   âœ… ALL SUGGESTIONS: Zero information loss (tracks preserved via merge)\n"
     ]
    }
   ],
   "source": [
    "# Display comprehensive deletion/consolidation recommendations\n",
    "if consolidation_suggestions:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“‹ CONSOLIDATION RECOMMENDATIONS (AGGRESSIVE - Zero Track Loss)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    df = pd.DataFrame(consolidation_suggestions)\n",
    "    df = df.sort_values(['tracks_lost', 'playlist_name'])\n",
    "    \n",
    "    # Separate by action type\n",
    "    delete_actions = df[df['action'] == 'delete']\n",
    "    merge_actions = df[df['action'] == 'merge']\n",
    "    \n",
    "    if len(delete_actions) > 0:\n",
    "        print(f\"\\nğŸ—‘ï¸  SAFE TO DELETE ({len(delete_actions)} playlists - 0 tracks lost):\")\n",
    "        print(\"-\" * 80)\n",
    "        for _, row in delete_actions.iterrows():\n",
    "            print(f\"   â€¢ {row['playlist_name']}\")\n",
    "            print(f\"     â†’ {row['reason']}\")\n",
    "            print(f\"     â†’ Keep: {row['alternative']}\")\n",
    "            print()\n",
    "    \n",
    "    if len(merge_actions) > 0:\n",
    "        print(f\"\\nğŸ”€ MERGE RECOMMENDATIONS ({len(merge_actions)} playlists - Zero track loss after adding missing tracks):\")\n",
    "        print(\"-\" * 80)\n",
    "        zero_loss_merges = merge_actions[merge_actions['tracks_lost'] == 0]\n",
    "        tracks_to_add_merges = merge_actions[merge_actions['tracks_lost'] > 0]\n",
    "        \n",
    "        if len(zero_loss_merges) > 0:\n",
    "            print(f\"\\n   âœ… Perfect merges (0 tracks to add - {len(zero_loss_merges)} playlists):\")\n",
    "            for _, row in zero_loss_merges.head(10).iterrows():\n",
    "                print(f\"      â€¢ {row['playlist_name']}\")\n",
    "                print(f\"        â†’ {row['reason']}\")\n",
    "                print(f\"        â†’ {row['alternative']}\")\n",
    "            if len(zero_loss_merges) > 10:\n",
    "                print(f\"      ... and {len(zero_loss_merges) - 10} more perfect merges\")\n",
    "        \n",
    "        if len(tracks_to_add_merges) > 0:\n",
    "            print(f\"\\n   ğŸ”„ Consolidation merges (add missing tracks - {len(tracks_to_add_merges)} playlists):\")\n",
    "            for _, row in tracks_to_add_merges.head(15).iterrows():\n",
    "                print(f\"      â€¢ {row['playlist_name']}\")\n",
    "                print(f\"        â†’ {row['reason']}\")\n",
    "                print(f\"        â†’ Add {row['tracks_lost']} tracks: {row['alternative']}\")\n",
    "            if len(tracks_to_add_merges) > 15:\n",
    "                print(f\"      ... and {len(tracks_to_add_merges) - 15} more consolidation merges\")\n",
    "        print()\n",
    "    \n",
    "    # Summary statistics\n",
    "    total_tracks_to_add = df['tracks_lost'].sum()\n",
    "    zero_loss = len(df[df['tracks_lost'] == 0])\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“Š AGGRESSIVE CONSOLIDATION SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"   Total playlists recommended for deletion/merge: {len(df)}\")\n",
    "    print(f\"   Perfect merges (0 tracks to add): {zero_loss}\")\n",
    "    print(f\"   Consolidation merges (add missing tracks): {len(df) - zero_loss}\")\n",
    "    print(f\"   Total unique tracks to add (zero loss after merge): {total_tracks_to_add}\")\n",
    "    print(f\"   Current total playlists: {len(playlist_info)}\")\n",
    "    print(f\"   After consolidation: {len(playlist_info) - len(df)} playlists\")\n",
    "    print(f\"   Reduction: {len(df)} playlists ({100*len(df)/len(playlist_info):.1f}%)\")\n",
    "    print(f\"   âœ… ALL SUGGESTIONS: Zero information loss (tracks preserved via merge)\")\n",
    "else:\n",
    "    print(\"\\nâœ… No consolidation recommendations - your library is well organized!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Find Group Consolidation Opportunities\n",
    "\n",
    "Find groups of small playlists that can be consolidated together into larger playlists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Finding group consolidation opportunities...\n",
      "   (Multiple small playlists that can merge into a single larger playlist)\n",
      "\n",
      "âœ… Found 5 group consolidation opportunities!\n",
      "\n",
      "================================================================================\n",
      "ğŸ“¦ GROUP CONSOLIDATION OPPORTUNITIES\n",
      "================================================================================\n",
      "   (Multiple small playlists can merge into a single larger playlist)\n",
      "\n",
      "1. Target: HiğŸ€ (765 tracks)\n",
      "   â†’ Can consolidate 5 playlists into this one:\n",
      "      1. Pop ig dont deep it (225 tracks)\n",
      "      2. ğŸ±skillz  (219 tracks)\n",
      "      3. HapPi â˜ºï¸ (224 tracks)\n",
      "      4. Musi(c)ngs (234 tracks)\n",
      "      5. Four 2060 Nine V2 (104 tracks)\n",
      "   â†’ Total tracks to add: 341 (zero loss)\n",
      "   â†’ Reduction: 5 playlists â†’ 1 playlist\n",
      "\n",
      "2. Target: Jams ğŸ“ (491 tracks)\n",
      "   â†’ Can consolidate 4 playlists into this one:\n",
      "      1. DarkThots (ALLdTIME) (48 tracks)\n",
      "      2. hrDnc ğŸš¨ (99 tracks)\n",
      "      3. Aura ğŸ§¿ğŸ¦‹ğŸŒğŸª¬ (154 tracks)\n",
      "      4. Bnce (62 tracks)\n",
      "   â†’ Total tracks to add: 172 (zero loss)\n",
      "   â†’ Reduction: 4 playlists â†’ 1 playlist\n",
      "\n",
      "3. Target: InMyRoom ğŸ’½ (366 tracks)\n",
      "   â†’ Can consolidate 3 playlists into this one:\n",
      "      1. Jan26 (92 tracks)\n",
      "      2. Trapsoul (57 tracks)\n",
      "      3. Flo (100 tracks)\n",
      "   â†’ Total tracks to add: 60 (zero loss)\n",
      "   â†’ Reduction: 3 playlists â†’ 1 playlist\n",
      "\n",
      "4. Target: ChillSunHop V2 (882 tracks)\n",
      "   â†’ Can consolidate 3 playlists into this one:\n",
      "      1. Sneeeeeek ğŸ‘Ÿ (106 tracks)\n",
      "      2. Ride the ğŸŒŠ  (283 tracks)\n",
      "      3. GrimeCrime (127 tracks)\n",
      "   â†’ Total tracks to add: 144 (zero loss)\n",
      "   â†’ Reduction: 3 playlists â†’ 1 playlist\n",
      "\n",
      "5. Target: WatsUrFlvr? V3 (616 tracks)\n",
      "   â†’ Can consolidate 2 playlists into this one:\n",
      "      1. Bossassob (201 tracks)\n",
      "      2. SadBoi2 (170 tracks)\n",
      "   â†’ Total tracks to add: 132 (zero loss)\n",
      "   â†’ Reduction: 2 playlists â†’ 1 playlist\n",
      "\n",
      "ğŸ“Š Group Consolidation Summary:\n",
      "   Total groups: 5\n",
      "   Total playlists that can be consolidated: 17\n",
      "   Reduction: 17 playlists â†’ 5 playlists\n",
      "   âœ… Zero information loss - all tracks preserved\n"
     ]
    }
   ],
   "source": [
    "# Find groups of small playlists that can be consolidated into larger playlists\n",
    "# Strategy: Identify multiple small playlists that together would fit well into a larger playlist\n",
    "\n",
    "print(\"ğŸ” Finding group consolidation opportunities...\")\n",
    "print(\"   (Multiple small playlists that can merge into a single larger playlist)\\n\")\n",
    "\n",
    "# Build a map of which playlists can merge into which\n",
    "merge_targets = {}  # target_pid -> list of (source_pid, missing_tracks)\n",
    "for suggestion in consolidation_suggestions:\n",
    "    if suggestion['action'] == 'merge' and suggestion['tracks_lost'] >= 0:\n",
    "        # Extract target playlist name from alternative\n",
    "        alt = suggestion['alternative']\n",
    "        if 'Merge into \"' in alt:\n",
    "            target_name = alt.split('Merge into \"')[1].split('\"')[0]\n",
    "        else:\n",
    "            target_name = alt\n",
    "        \n",
    "        # Find target playlist ID\n",
    "        target_pid = None\n",
    "        for pid, info in playlist_info.items():\n",
    "            if info['name'] == target_name:\n",
    "                target_pid = pid\n",
    "                break\n",
    "        \n",
    "        if target_pid:\n",
    "            if target_pid not in merge_targets:\n",
    "                merge_targets[target_pid] = []\n",
    "            merge_targets[target_pid].append((suggestion['playlist_id'], suggestion['tracks_lost']))\n",
    "\n",
    "# Find groups: multiple small playlists targeting the same larger playlist\n",
    "# EXCLUDE auto-generated playlists as targets\n",
    "group_consolidations = []\n",
    "for target_pid, sources in merge_targets.items():\n",
    "    # Skip if target is auto-generated - don't suggest merging into auto-generated playlists\n",
    "    if is_auto_generated_playlist(target_pid):\n",
    "        continue\n",
    "    \n",
    "    # Filter out auto-generated playlists from sources\n",
    "    valid_sources = [(pid, missing) for pid, missing in sources if not is_auto_generated_playlist(pid)]\n",
    "    \n",
    "    if len(valid_sources) >= 2:  # At least 2 valid playlists can merge into this target\n",
    "        target_info = playlist_info[target_pid]\n",
    "        total_tracks_to_add = sum(missing for _, missing in valid_sources)\n",
    "        source_names = [playlist_info[pid]['name'] for pid, _ in valid_sources]\n",
    "        source_tracks = [playlist_info[pid]['track_count'] for pid, _ in valid_sources]\n",
    "        \n",
    "        group_consolidations.append({\n",
    "            'target_name': target_info['name'],\n",
    "            'target_tracks': target_info['track_count'],\n",
    "            'source_count': len(valid_sources),\n",
    "            'source_names': source_names,\n",
    "            'source_tracks': source_tracks,\n",
    "            'total_tracks_to_add': total_tracks_to_add,\n",
    "            'target_pid': target_pid,\n",
    "            'source_pids': [pid for pid, _ in valid_sources]\n",
    "        })\n",
    "\n",
    "if group_consolidations:\n",
    "    print(f\"âœ… Found {len(group_consolidations)} group consolidation opportunities!\\n\")\n",
    "    \n",
    "    # Sort by number of sources (most consolidation first)\n",
    "    group_consolidations.sort(key=lambda x: x['source_count'], reverse=True)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ“¦ GROUP CONSOLIDATION OPPORTUNITIES\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"   (Multiple small playlists can merge into a single larger playlist)\\n\")\n",
    "    \n",
    "    for i, group in enumerate(group_consolidations[:20], 1):  # Show top 20\n",
    "        print(f\"{i}. Target: {group['target_name']} ({group['target_tracks']} tracks)\")\n",
    "        print(f\"   â†’ Can consolidate {group['source_count']} playlists into this one:\")\n",
    "        for j, (name, tracks) in enumerate(zip(group['source_names'], group['source_tracks']), 1):\n",
    "            print(f\"      {j}. {name} ({tracks} tracks)\")\n",
    "        print(f\"   â†’ Total tracks to add: {group['total_tracks_to_add']} (zero loss)\")\n",
    "        print(f\"   â†’ Reduction: {group['source_count']} playlists â†’ 1 playlist\")\n",
    "        print()\n",
    "    \n",
    "    if len(group_consolidations) > 20:\n",
    "        print(f\"   ... and {len(group_consolidations) - 20} more group opportunities\\n\")\n",
    "    \n",
    "    # Summary\n",
    "    total_groups = len(group_consolidations)\n",
    "    total_sources = sum(g['source_count'] for g in group_consolidations)\n",
    "    print(f\"ğŸ“Š Group Consolidation Summary:\")\n",
    "    print(f\"   Total groups: {total_groups}\")\n",
    "    print(f\"   Total playlists that can be consolidated: {total_sources}\")\n",
    "    print(f\"   Reduction: {total_sources} playlists â†’ {total_groups} playlists\")\n",
    "    print(f\"   âœ… Zero information loss - all tracks preserved\")\n",
    "else:\n",
    "    print(\"âœ… No group consolidation opportunities found\")\n",
    "    print(\"   (Individual merges are more efficient)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Consolidation Strategies for Similar Playlists\n",
    "\n",
    "Find similar user-created playlists (>40% similarity) that could be consolidated together for better organization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Finding consolidation strategies for similar playlists...\n",
      "   (Playlists with 40-50% similarity - good candidates for manual review)\n",
      "\n",
      "âœ… Found 27 similar playlist pairs for consolidation strategies!\n",
      "\n",
      "================================================================================\n",
      "ğŸ”„ CONSOLIDATION STRATEGIES FOR SIMILAR PLAYLISTS\n",
      "================================================================================\n",
      "   (User-created playlists only - auto-generated 'AJ' playlists excluded)\n",
      "\n",
      "\n",
      "ğŸ“¦ COMBINE PLAYLISTS (Similar sizes - 6 pairs):\n",
      "--------------------------------------------------------------------------------\n",
      "1. Create combined playlist with tracks from both 'IcedLemonadeğŸ‹' and 'SummerChill ğŸŒğŸ¥¶'\n",
      "   â€¢ 'IcedLemonadeğŸ‹' (503 tracks) + 'SummerChill ğŸŒğŸ¥¶' (458 tracks)\n",
      "   â€¢ Similarity: 49.5%\n",
      "   â€¢ Total unique tracks if combined: ~958 (zero loss)\n",
      "\n",
      "2. Create combined playlist with tracks from both 'WatsUrFlvr? V3' and '2Silk2Velvet'\n",
      "   â€¢ 'WatsUrFlvr? V3' (616 tracks) + '2Silk2Velvet' (524 tracks)\n",
      "   â€¢ Similarity: 49.0%\n",
      "   â€¢ Total unique tracks if combined: ~1137 (zero loss)\n",
      "\n",
      "3. Create combined playlist with tracks from both 'HiğŸ€' and 'StylinğŸ¤™'\n",
      "   â€¢ 'HiğŸ€' (765 tracks) + 'StylinğŸ¤™' (634 tracks)\n",
      "   â€¢ Similarity: 48.0%\n",
      "   â€¢ Total unique tracks if combined: ~1395 (zero loss)\n",
      "\n",
      "4. Create combined playlist with tracks from both 'WatsUrFlvr? V3' and 'RvRChrls3 ğŸ¦¦'\n",
      "   â€¢ 'WatsUrFlvr? V3' (616 tracks) + 'RvRChrls3 ğŸ¦¦' (561 tracks)\n",
      "   â€¢ Similarity: 47.9%\n",
      "   â€¢ Total unique tracks if combined: ~1174 (zero loss)\n",
      "\n",
      "5. Create combined playlist with tracks from both 'IcedLemonadeğŸ‹' and 'Flwrs4UğŸŒ¸'\n",
      "   â€¢ 'IcedLemonadeğŸ‹' (503 tracks) + 'Flwrs4UğŸŒ¸' (397 tracks)\n",
      "   â€¢ Similarity: 45.6%\n",
      "   â€¢ Total unique tracks if combined: ~898 (zero loss)\n",
      "\n",
      "6. Create combined playlist with tracks from both 'StylinğŸ¤™' and 'WatsUrFlvr? V3'\n",
      "   â€¢ 'StylinğŸ¤™' (634 tracks) + 'WatsUrFlvr? V3' (616 tracks)\n",
      "   â€¢ Similarity: 45.0%\n",
      "   â€¢ Total unique tracks if combined: ~1247 (zero loss)\n",
      "\n",
      "\n",
      "ğŸ” REVIEW FOR CONSOLIDATION (Lower similarity - 21 pairs):\n",
      "--------------------------------------------------------------------------------\n",
      "1. Chill Dance (231 tracks) â†” Ghar2ğŸ¡ (424 tracks)\n",
      "   â€¢ Similarity: 49.9%\n",
      "   â€¢ Overlap: P1â†’P2: 94.4%, P2â†’P1: 51.4%\n",
      "   â€¢ Recommendation: Review manually - may serve different purposes\n",
      "\n",
      "2. WatsUrFlvr? V3 (616 tracks) â†” Flwrs4UğŸŒ¸ (397 tracks)\n",
      "   â€¢ Similarity: 45.1%\n",
      "   â€¢ Overlap: P1â†’P2: 51.1%, P2â†’P1: 79.3%\n",
      "   â€¢ Recommendation: Review manually - may serve different purposes\n",
      "\n",
      "3. InMyRoom ğŸ’½ (366 tracks) â†” Flwrs4UğŸŒ¸ (397 tracks)\n",
      "   â€¢ Similarity: 44.8%\n",
      "   â€¢ Overlap: P1â†’P2: 64.5%, P2â†’P1: 59.4%\n",
      "   â€¢ Recommendation: Review manually - may serve different purposes\n",
      "\n",
      "4. StylinğŸ¤™ (634 tracks) â†” GLyD3 (515 tracks)\n",
      "   â€¢ Similarity: 44.7%\n",
      "   â€¢ Overlap: P1â†’P2: 56.0%, P2â†’P1: 68.9%\n",
      "   â€¢ Recommendation: Review manually - may serve different purposes\n",
      "\n",
      "5. PWR4 (433 tracks) â†” WUT4 (507 tracks)\n",
      "   â€¢ Similarity: 44.6%\n",
      "   â€¢ Overlap: P1â†’P2: 67.0%, P2â†’P1: 57.2%\n",
      "   â€¢ Recommendation: Review manually - may serve different purposes\n",
      "\n",
      "6. IcedLemonadeğŸ‹ (503 tracks) â†” WatsUrFlvr? V3 (616 tracks)\n",
      "   â€¢ Similarity: 44.6%\n",
      "   â€¢ Overlap: P1â†’P2: 68.6%, P2â†’P1: 56.0%\n",
      "   â€¢ Recommendation: Review manually - may serve different purposes\n",
      "\n",
      "7. InMyRoom ğŸ’½ (366 tracks) â†” WatsUrFlvr? V3 (616 tracks)\n",
      "   â€¢ Similarity: 44.2%\n",
      "   â€¢ Overlap: P1â†’P2: 82.2%, P2â†’P1: 48.9%\n",
      "   â€¢ Recommendation: Review manually - may serve different purposes\n",
      "\n",
      "8. ChillSunHop V2 (882 tracks) â†” OnDStreetğŸš¦ (496 tracks)\n",
      "   â€¢ Similarity: 44.0%\n",
      "   â€¢ Overlap: P1â†’P2: 47.7%, P2â†’P1: 84.9%\n",
      "   â€¢ Recommendation: Review manually - may serve different purposes\n",
      "\n",
      "9. FeelDForce âš¡ï¸ (442 tracks) â†” PWR4 (433 tracks)\n",
      "   â€¢ Similarity: 43.7%\n",
      "   â€¢ Overlap: P1â†’P2: 60.2%, P2â†’P1: 61.4%\n",
      "   â€¢ Recommendation: Review manually - may serve different purposes\n",
      "\n",
      "10. IcedLemonadeğŸ‹ (503 tracks) â†” 2Silk2Velvet (524 tracks)\n",
      "   â€¢ Similarity: 43.6%\n",
      "   â€¢ Overlap: P1â†’P2: 62.0%, P2â†’P1: 59.5%\n",
      "   â€¢ Recommendation: Review manually - may serve different purposes\n",
      "\n",
      "11. ChillSunHop V2 (882 tracks) â†” HiğŸ€ (765 tracks)\n",
      "   â€¢ Similarity: 43.3%\n",
      "   â€¢ Overlap: P1â†’P2: 56.5%, P2â†’P1: 65.1%\n",
      "   â€¢ Recommendation: Review manually - may serve different purposes\n",
      "\n",
      "12. RvRChrls3 ğŸ¦¦ (561 tracks) â†” 2Silk2Velvet (524 tracks)\n",
      "   â€¢ Similarity: 43.3%\n",
      "   â€¢ Overlap: P1â†’P2: 58.5%, P2â†’P1: 62.6%\n",
      "   â€¢ Recommendation: Review manually - may serve different purposes\n",
      "\n",
      "13. InMyRoom ğŸ’½ (366 tracks) â†” RvRChrls3 ğŸ¦¦ (561 tracks)\n",
      "   â€¢ Similarity: 43.1%\n",
      "   â€¢ Overlap: P1â†’P2: 76.2%, P2â†’P1: 49.7%\n",
      "   â€¢ Recommendation: Review manually - may serve different purposes\n",
      "\n",
      "14. Ride ğŸš´â€â™‚ï¸ (651 tracks) â†” HiğŸ€ (765 tracks)\n",
      "   â€¢ Similarity: 42.6%\n",
      "   â€¢ Overlap: P1â†’P2: 65.0%, P2â†’P1: 55.3%\n",
      "   â€¢ Recommendation: Review manually - may serve different purposes\n",
      "\n",
      "15. InMyRoom ğŸ’½ (366 tracks) â†” 2Silk2Velvet (524 tracks)\n",
      "   â€¢ Similarity: 42.4%\n",
      "   â€¢ Overlap: P1â†’P2: 72.4%, P2â†’P1: 50.6%\n",
      "   â€¢ Recommendation: Review manually - may serve different purposes\n",
      "\n",
      "   ... and 6 more pairs to review\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š CONSOLIDATION STRATEGIES SUMMARY\n",
      "================================================================================\n",
      "   Total similar pairs found: 27\n",
      "   High/Medium confidence merges: 0\n",
      "   Combine opportunities: 6\n",
      "   Review candidates: 21\n",
      "   âœ… All strategies exclude auto-generated 'AJ' playlists\n",
      "   ğŸ’¡ Review recommendations manually before consolidating\n"
     ]
    }
   ],
   "source": [
    "# Consolidation strategies for similar playlists (40-50% similarity)\n",
    "# Use helper function to build consolidation strategies\n",
    "from notebook_helpers import build_consolidation_strategies\n",
    "\n",
    "print(\"ğŸ” Finding consolidation strategies for similar playlists...\")\n",
    "print(\"   (Playlists with 40-50% similarity - good candidates for manual review)\\n\")\n",
    "\n",
    "# Build consolidation strategies using helper function\n",
    "strategies_results = build_consolidation_strategies(redundancy_results, consolidation_results)\n",
    "similar_consolidation_candidates = strategies_results['similar_consolidation_candidates']\n",
    "    \n",
    "if similar_consolidation_candidates:\n",
    "    print(f\"âœ… Found {len(similar_consolidation_candidates)} similar playlist pairs for consolidation strategies!\\n\")\n",
    "    \n",
    "    # Sort by similarity (highest first)\n",
    "    similar_consolidation_candidates.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "    \n",
    "    # Group by strategy\n",
    "    merge_into_larger = [c for c in similar_consolidation_candidates if c['strategy'] == 'merge_into_larger']\n",
    "    combine = [c for c in similar_consolidation_candidates if c['strategy'] == 'combine']\n",
    "    review = [c for c in similar_consolidation_candidates if c['strategy'] == 'review']\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ”„ CONSOLIDATION STRATEGIES FOR SIMILAR PLAYLISTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"   (User-created playlists only - auto-generated 'AJ' playlists excluded)\\n\")\n",
    "    \n",
    "    if merge_into_larger:\n",
    "        print(f\"ğŸ“Œ MERGE INTO LARGER (High/Medium Confidence - {len(merge_into_larger)} pairs):\")\n",
    "        print(\"-\" * 80)\n",
    "        for i, candidate in enumerate(merge_into_larger[:20], 1):  # Show top 20\n",
    "            print(f\"{i}. {candidate['recommended_action']}\")\n",
    "            print(f\"   â€¢ Similarity: {candidate['similarity']:.1f}%\")\n",
    "            print(f\"   â€¢ Overlap: {max(candidate['overlap1'], candidate['overlap2']):.1f}%\")\n",
    "            print(f\"   â€¢ Tracks to add: {candidate['tracks_to_add']} (zero loss)\")\n",
    "            print(f\"   â€¢ Confidence: {candidate['confidence']}\")\n",
    "            print()\n",
    "        if len(merge_into_larger) > 20:\n",
    "            print(f\"   ... and {len(merge_into_larger) - 20} more merge opportunities\\n\")\n",
    "    \n",
    "    if combine:\n",
    "        print(f\"\\nğŸ“¦ COMBINE PLAYLISTS (Similar sizes - {len(combine)} pairs):\")\n",
    "        print(\"-\" * 80)\n",
    "        for i, candidate in enumerate(combine[:15], 1):  # Show top 15\n",
    "            print(f\"{i}. {candidate['recommended_action']}\")\n",
    "            print(f\"   â€¢ '{candidate['playlist1']}' ({candidate['tracks1']} tracks) + '{candidate['playlist2']}' ({candidate['tracks2']} tracks)\")\n",
    "            print(f\"   â€¢ Similarity: {candidate['similarity']:.1f}%\")\n",
    "            if candidate['unique_combined']:\n",
    "                print(f\"   â€¢ Total unique tracks if combined: ~{candidate['unique_combined']} (zero loss)\")\n",
    "            else:\n",
    "                overlap_tracks = int(candidate['tracks1'] * candidate['overlap1'] / 100)\n",
    "                unique_combined = candidate['tracks1'] + candidate['tracks2'] - overlap_tracks\n",
    "                print(f\"   â€¢ Total unique tracks if combined: ~{unique_combined} (zero loss)\")\n",
    "            print()\n",
    "        if len(combine) > 15:\n",
    "            print(f\"   ... and {len(combine) - 15} more combine opportunities\\n\")\n",
    "    \n",
    "    if review:\n",
    "        print(f\"\\nğŸ” REVIEW FOR CONSOLIDATION (Lower similarity - {len(review)} pairs):\")\n",
    "        print(\"-\" * 80)\n",
    "        for i, candidate in enumerate(review[:15], 1):  # Show top 15\n",
    "            print(f\"{i}. {candidate['playlist1']} ({candidate['tracks1']} tracks) â†” {candidate['playlist2']} ({candidate['tracks2']} tracks)\")\n",
    "            print(f\"   â€¢ Similarity: {candidate['similarity']:.1f}%\")\n",
    "            print(f\"   â€¢ Overlap: P1â†’P2: {candidate['overlap1']:.1f}%, P2â†’P1: {candidate['overlap2']:.1f}%\")\n",
    "            print(f\"   â€¢ Recommendation: Review manually - may serve different purposes\")\n",
    "            print()\n",
    "        if len(review) > 15:\n",
    "            print(f\"   ... and {len(review) - 15} more pairs to review\\n\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ“Š CONSOLIDATION STRATEGIES SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"   Total similar pairs found: {len(similar_consolidation_candidates)}\")\n",
    "    print(f\"   High/Medium confidence merges: {len(merge_into_larger)}\")\n",
    "    print(f\"   Combine opportunities: {len(combine)}\")\n",
    "    print(f\"   Review candidates: {len(review)}\")\n",
    "    print(f\"   âœ… All strategies exclude auto-generated 'AJ' playlists\")\n",
    "    print(f\"   ğŸ’¡ Review recommendations manually before consolidating\")\n",
    "else:\n",
    "    print(\"âœ… No similar playlist pairs found for consolidation strategies\")\n",
    "    print(\"   (Only user-created playlists analyzed, excluding auto-generated 'AJ' playlists)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Detailed Track-Level Analysis\n",
    "\n",
    "For merge recommendations, let's see exactly which tracks would need to be added.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 560 playlists, 5,548 tracks\n",
      "ğŸ“‹ Detailed Merge Analysis (tracks that need to be added):\n",
      "================================================================================\n",
      "\n",
      "ğŸ—‘ï¸  Delete: Jan26\n",
      "   â†’ Merge into: InMyRoom ğŸ’½\n",
      "   â†’ Add 26 tracks\n",
      "   â†’ Sample: Give Up the Goods (Just Step) (feat. Big Noyd), light years (feat. InÃ©z), HYPNOSIS, The Less I Know The Better, If U Need It...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: Trapsoul\n",
      "   â†’ Merge into: InMyRoom ğŸ’½\n",
      "   â†’ Add 9 tracks\n",
      "   â†’ Sample: A$AP Forever (feat. Moby), Sk8 (with Ciara & EARTHGANG), Geneva (feat. Eli Sostre), Tailor Swif, ZZZ...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: DarkThots (ALLdTIME)\n",
      "   â†’ Merge into: Jams ğŸ“\n",
      "   â†’ Add 20 tracks\n",
      "   â†’ Sample: Talk of the Town, HYPNOSIS, You Give Me A Feeling, OK OK, Arya...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: Pop ig dont deep it\n",
      "   â†’ Merge into: HiğŸ€\n",
      "   â†’ Add 67 tracks\n",
      "   â†’ Sample: The Lazy Song, If U Need It, dollaz n dollaz, The Days - NOTION Remix, Moves Like Jagger - Studio Recording From \"The Voice\" Performance...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: Loungin\n",
      "   â†’ Merge into: Pop ig dont deep it\n",
      "   â†’ Add 5 tracks\n",
      "   â†’ Sample: FRENCH BOSSA NOVA, Pictures of You, The Beast - Digitally Remastered 95, Dream, Wave...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: Flo\n",
      "   â†’ Merge into: InMyRoom ğŸ’½\n",
      "   â†’ Add 25 tracks\n",
      "   â†’ Sample: Every Breath You Take, CanopÃ©e, Is It Too Late for Me, Can't Love Myself, Loosing Interest...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: hrDnc ğŸš¨\n",
      "   â†’ Merge into: Jams ğŸ“\n",
      "   â†’ Add 49 tracks\n",
      "   â†’ Sample: Diamonds On My Mind, Match My Speed, Back 2 Back, X-Rated, i cant tell (love my money)...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: JazzyğŸ·\n",
      "   â†’ Merge into: IcedLemonadeğŸ‹\n",
      "   â†’ Add 5 tracks\n",
      "   â†’ Sample: On the Nature of Daylight, Strangers In The Night, Blue And Sentimental, Ain't No Love In The Heart Of The City - Single Version, Sunny...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: Aura ğŸ§¿ğŸ¦‹ğŸŒğŸª¬\n",
      "   â†’ Merge into: Jams ğŸ“\n",
      "   â†’ Add 76 tracks\n",
      "   â†’ Sample: Yam Yam, CanopÃ©e, Electric U, he'll give us what we really need, Dontcha...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: Bnce\n",
      "   â†’ Merge into: Jams ğŸ“\n",
      "   â†’ Add 27 tracks\n",
      "   â†’ Sample: See You Again, Chicken Suya, On My Mind (Jorja Smith X Preditah), Primo, I. The Itis...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: Sneeeeeek ğŸ‘Ÿ\n",
      "   â†’ Merge into: ChillSunHop V2\n",
      "   â†’ Add 24 tracks\n",
      "   â†’ Sample: 93 'Til Infinity, Busta's Lament, DEAD MAN WALKING, New Sky (feat. Kadhja Bonet), Cowboy Bebop...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: Ride the ğŸŒŠ \n",
      "   â†’ Merge into: ChillSunHop V2\n",
      "   â†’ Add 79 tracks\n",
      "   â†’ Sample: Afraid To Feel, 93 'Til Infinity, Let Me Fly, Infrunami, Somebody Else (with Jorja Smith & Lil Durk)...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: GrimeCrime\n",
      "   â†’ Merge into: ChillSunHop V2\n",
      "   â†’ Add 41 tracks\n",
      "   â†’ Sample: Redemption (feat. Nemzzz), Die 4 The Bro, I Called Tj Twice, Toxic, 100 Degrees (feat. Sam Wise)...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: Save the ğŸŒ \n",
      "   â†’ Merge into: Ride ğŸš´â€â™‚ï¸\n",
      "   â†’ Add 73 tracks\n",
      "   â†’ Sample: Demons, Get You The Moon (feat. SnÃ¸w), Cult Classic, World Hold On (Children Of The Sky) - Radio Edit - Vintage Culture & Dubdogz Remix, Maggot Brain...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: ğŸ±skillz \n",
      "   â†’ Merge into: HiğŸ€\n",
      "   â†’ Add 59 tracks\n",
      "   â†’ Sample: The Lazy Song, Safe and Sound, Contigo, Don't, HOT WIND BLOWS (feat. Lil Wayne)...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: HapPi â˜ºï¸\n",
      "   â†’ Merge into: HiğŸ€\n",
      "   â†’ Add 70 tracks\n",
      "   â†’ Sample: The Lazy Song, Safe and Sound, Don't, Million Miles Away - Edit, he'll give us what we really need...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: Musi(c)ngs\n",
      "   â†’ Merge into: HiğŸ€\n",
      "   â†’ Add 98 tracks\n",
      "   â†’ Sample: 93 'Til Infinity, Every Breath You Take, Will I See You Again?, Demons, 3 Letters...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: Four 2060 Nine V2\n",
      "   â†’ Merge into: HiğŸ€\n",
      "   â†’ Add 47 tracks\n",
      "   â†’ Sample: love nwantiti (ah ah ah), Lights Out, Start Over, Heart To Heart, CPR...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: OldSoulğŸ“»\n",
      "   â†’ Merge into: Musi(c)ngs\n",
      "   â†’ Add 14 tracks\n",
      "   â†’ Sample: Sultans Of Swing, Paradise, Blue Velvet, This Feeling, Strangers In The Night...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: Joooonâ˜€ï¸\n",
      "   â†’ Merge into: OnDStreetğŸš¦\n",
      "   â†’ Add 14 tracks\n",
      "   â†’ Sample: 19.10, Beauty Rains, Someone To Spend Time With, amphetamine, Get Down...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: Bossassob\n",
      "   â†’ Merge into: WatsUrFlvr? V3\n",
      "   â†’ Add 90 tracks\n",
      "   â†’ Sample: Buzzed, dehydrate, Interludio De Medicamento, Gypsy Woman - Quarantine Sessions, Alto songo...\n",
      "\n",
      "ğŸ—‘ï¸  Delete: SadBoi2\n",
      "   â†’ Merge into: WatsUrFlvr? V3\n",
      "   â†’ Add 42 tracks\n",
      "   â†’ Sample: Every Breath You Take, Who's Lovin' You, Drown In My Own Tears, It Hurts Me Too, Mean It In The Morning...\n",
      "\n",
      "ğŸ—‘ï¸  Delete:  STFU\n",
      "   â†’ Merge into: SandTrap ğŸï¸ğŸ‡¹ğŸ‡­\n",
      "   â†’ Add 8 tracks\n",
      "   â†’ Sample: ALL GIRLS ARE THE SAME, P.S Fuck You Cunt, So Good, Beware, Fuck You Bitch...\n"
     ]
    }
   ],
   "source": [
    "# For merge actions, show which tracks need to be added\n",
    "# Load tracks data to get track names\n",
    "from spotim8.analysis import LibraryAnalyzer\n",
    "\n",
    "analyzer = LibraryAnalyzer(DATA_DIR).load()\n",
    "tracks_df = analyzer.tracks_all\n",
    "\n",
    "merge_details = []\n",
    "\n",
    "for suggestion in consolidation_suggestions:\n",
    "    if suggestion['action'] == 'merge' and suggestion['tracks_lost'] > 0:\n",
    "        delete_pid = suggestion['playlist_id']\n",
    "        delete_tracks = playlist_track_sets[delete_pid]\n",
    "        \n",
    "        # Find the playlist to merge into\n",
    "        keep_name = suggestion['alternative'].split('\"')[1] if '\"' in suggestion['alternative'] else suggestion['alternative']\n",
    "        keep_pid = None\n",
    "        for pid, info in playlist_info.items():\n",
    "            if info['name'] == keep_name:\n",
    "                keep_pid = pid\n",
    "                break\n",
    "        \n",
    "        if keep_pid:\n",
    "            keep_tracks = playlist_track_sets[keep_pid]\n",
    "            missing_tracks = delete_tracks - keep_tracks\n",
    "            \n",
    "            if missing_tracks:\n",
    "                # Get track names\n",
    "                missing_track_ids = list(missing_tracks)[:10]  # Show first 10\n",
    "                track_names_df = tracks_df[tracks_df['track_id'].isin(missing_track_ids)]\n",
    "                track_names = track_names_df['name'].tolist() if len(track_names_df) > 0 else []\n",
    "                \n",
    "                merge_details.append({\n",
    "                    'Delete': suggestion['playlist_name'],\n",
    "                    'Merge Into': keep_name,\n",
    "                    'Missing Tracks': len(missing_tracks),\n",
    "                    'Sample Tracks': ', '.join(track_names[:5]) if track_names else 'N/A'\n",
    "                })\n",
    "\n",
    "if merge_details:\n",
    "    print(\"ğŸ“‹ Detailed Merge Analysis (tracks that need to be added):\")\n",
    "    print(\"=\" * 80)\n",
    "    df = pd.DataFrame(merge_details)\n",
    "    for _, row in df.iterrows():\n",
    "        print(f\"\\nğŸ—‘ï¸  Delete: {row['Delete']}\")\n",
    "        print(f\"   â†’ Merge into: {row['Merge Into']}\")\n",
    "        print(f\"   â†’ Add {row['Missing Tracks']} tracks\")\n",
    "        if row['Sample Tracks'] != 'N/A':\n",
    "            print(f\"   â†’ Sample: {row['Sample Tracks']}...\")\n",
    "else:\n",
    "    print(\"âœ… All merge recommendations have zero track loss!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Aggressive Reorganization Strategy\n",
    "\n",
    "Based on the aggressive analysis, here's a comprehensive reorganization plan to maximize playlist reduction without losing information.\n",
    "\n",
    "**NOTE:** Auto-generated playlists starting with \"AJ\" prefix are excluded from all recommendations - they're managed by the sync script and should not be deleted or consolidated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ“‹ AGGRESSIVE REORGANIZATION PLAN (Zero Information Loss)\n",
      "================================================================================\n",
      "\n",
      "ğŸ—‘ï¸  DELETE (0 playlists - 0 tracks lost):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "ğŸ”€ MERGE (23 playlists - Zero loss after merge):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "   ğŸ“¦ Target: HiğŸ€\n",
      "      â†’ Consolidate 5 playlists into this one:\n",
      "        â€¢ Pop ig dont deep it (Small playlist (225 tracks) with 70.2% overlap in larger \"HiğŸ€\" (765 tracks))\n",
      "          â†’ Add 67 tracks\n",
      "        â€¢ ğŸ±skillz  (Small playlist (219 tracks) with 73.1% overlap in larger \"HiğŸ€\" (765 tracks))\n",
      "          â†’ Add 59 tracks\n",
      "        â€¢ HapPi â˜ºï¸ (Small playlist (224 tracks) with 68.8% overlap in larger \"HiğŸ€\" (765 tracks))\n",
      "          â†’ Add 70 tracks\n",
      "        â€¢ Musi(c)ngs (Small playlist (234 tracks) with 58.1% overlap in larger \"HiğŸ€\" (765 tracks))\n",
      "          â†’ Add 98 tracks\n",
      "        â€¢ Four 2060 Nine V2 (Small playlist (104 tracks) with 54.8% overlap in larger \"HiğŸ€\" (765 tracks))\n",
      "          â†’ Add 47 tracks\n",
      "      â†’ Total: Add 341 tracks (zero loss)\n",
      "\n",
      "   ğŸ“¦ Target: Jams ğŸ“\n",
      "      â†’ Consolidate 4 playlists into this one:\n",
      "        â€¢ DarkThots (ALLdTIME) (Small playlist (48 tracks) with 58.3% overlap in larger \"Jams ğŸ“\" (491 tracks))\n",
      "          â†’ Add 20 tracks\n",
      "        â€¢ hrDnc ğŸš¨ (Small playlist (99 tracks) with 50.5% overlap in larger \"Jams ğŸ“\" (491 tracks))\n",
      "          â†’ Add 49 tracks\n",
      "        â€¢ Aura ğŸ§¿ğŸ¦‹ğŸŒğŸª¬ (Small playlist (154 tracks) with 50.6% overlap in larger \"Jams ğŸ“\" (491 tracks))\n",
      "          â†’ Add 76 tracks\n",
      "        â€¢ Bnce (Small playlist (62 tracks) with 56.5% overlap in larger \"Jams ğŸ“\" (491 tracks))\n",
      "          â†’ Add 27 tracks\n",
      "      â†’ Total: Add 172 tracks (zero loss)\n",
      "\n",
      "   ğŸ“¦ Target: InMyRoom ğŸ’½\n",
      "      â†’ Consolidate 3 playlists into this one:\n",
      "        â€¢ Jan26 (Small playlist (92 tracks) with 71.7% overlap in larger \"InMyRoom ğŸ’½\" (366 tracks))\n",
      "          â†’ Add 26 tracks\n",
      "        â€¢ Trapsoul (Small playlist (57 tracks) with 84.2% overlap in larger \"InMyRoom ğŸ’½\" (366 tracks))\n",
      "          â†’ Add 9 tracks\n",
      "        â€¢ Flo (Small playlist (100 tracks) with 75.0% overlap in larger \"InMyRoom ğŸ’½\" (366 tracks))\n",
      "          â†’ Add 25 tracks\n",
      "      â†’ Total: Add 60 tracks (zero loss)\n",
      "\n",
      "   ğŸ“¦ Target: ChillSunHop V2\n",
      "      â†’ Consolidate 3 playlists into this one:\n",
      "        â€¢ Sneeeeeek ğŸ‘Ÿ (Small playlist (106 tracks) with 77.4% overlap in larger \"ChillSunHop V2\" (882 tracks))\n",
      "          â†’ Add 24 tracks\n",
      "        â€¢ Ride the ğŸŒŠ  (Small playlist (283 tracks) with 72.1% overlap in larger \"ChillSunHop V2\" (882 tracks))\n",
      "          â†’ Add 79 tracks\n",
      "        â€¢ GrimeCrime (Small playlist (127 tracks) with 67.7% overlap in larger \"ChillSunHop V2\" (882 tracks))\n",
      "          â†’ Add 41 tracks\n",
      "      â†’ Total: Add 144 tracks (zero loss)\n",
      "\n",
      "   ğŸ“¦ Target: WatsUrFlvr? V3\n",
      "      â†’ Consolidate 2 playlists into this one:\n",
      "        â€¢ Bossassob (Small playlist (201 tracks) with 55.2% overlap in larger \"WatsUrFlvr? V3\" (616 tracks))\n",
      "          â†’ Add 90 tracks\n",
      "        â€¢ SadBoi2 (Small playlist (170 tracks) with 75.3% overlap in larger \"WatsUrFlvr? V3\" (616 tracks))\n",
      "          â†’ Add 42 tracks\n",
      "      â†’ Total: Add 132 tracks (zero loss)\n",
      "\n",
      "   ğŸ“¦ Target: Pop ig dont deep it\n",
      "      â†’ Consolidate 1 playlists into this one:\n",
      "        â€¢ Loungin (Small playlist (11 tracks) with 54.5% overlap in larger \"Pop ig dont deep it\" (225 tracks))\n",
      "          â†’ Add 5 tracks\n",
      "      â†’ Total: Add 5 tracks (zero loss)\n",
      "\n",
      "   ğŸ“¦ Target: IcedLemonadeğŸ‹\n",
      "      â†’ Consolidate 1 playlists into this one:\n",
      "        â€¢ JazzyğŸ· (Small playlist (19 tracks) with 73.7% overlap in larger \"IcedLemonadeğŸ‹\" (503 tracks))\n",
      "          â†’ Add 5 tracks\n",
      "      â†’ Total: Add 5 tracks (zero loss)\n",
      "\n",
      "   ğŸ“¦ Target: Ride ğŸš´â€â™‚ï¸\n",
      "      â†’ Consolidate 1 playlists into this one:\n",
      "        â€¢ Save the ğŸŒ  (Small playlist (165 tracks) with 55.8% overlap in larger \"Ride ğŸš´â€â™‚ï¸\" (651 tracks))\n",
      "          â†’ Add 73 tracks\n",
      "      â†’ Total: Add 73 tracks (zero loss)\n",
      "\n",
      "   ğŸ“¦ Target: Musi(c)ngs\n",
      "      â†’ Consolidate 1 playlists into this one:\n",
      "        â€¢ OldSoulğŸ“» (Small playlist (32 tracks) with 56.2% overlap in larger \"Musi(c)ngs\" (234 tracks))\n",
      "          â†’ Add 14 tracks\n",
      "      â†’ Total: Add 14 tracks (zero loss)\n",
      "\n",
      "   ğŸ“¦ Target: OnDStreetğŸš¦\n",
      "      â†’ Consolidate 1 playlists into this one:\n",
      "        â€¢ Joooonâ˜€ï¸ (Small playlist (30 tracks) with 53.3% overlap in larger \"OnDStreetğŸš¦\" (496 tracks))\n",
      "          â†’ Add 14 tracks\n",
      "      â†’ Total: Add 14 tracks (zero loss)\n",
      "\n",
      "   ğŸ“¦ Target: SandTrap ğŸï¸ğŸ‡¹ğŸ‡­\n",
      "      â†’ Consolidate 1 playlists into this one:\n",
      "        â€¢  STFU (Small playlist (24 tracks) with 66.7% overlap in larger \"SandTrap ğŸï¸ğŸ‡¹ğŸ‡­\" (986 tracks))\n",
      "          â†’ Add 8 tracks\n",
      "      â†’ Total: Add 8 tracks (zero loss)\n",
      "\n",
      "\n",
      "âœ… KEEP (41 playlists after consolidation):\n",
      "--------------------------------------------------------------------------------\n",
      "   â€¢ TrapNeverDies3.0 (1140 tracks)\n",
      "   â€¢ SandTrap ğŸï¸ğŸ‡¹ğŸ‡­ (986 tracks)\n",
      "   â€¢ AltHop3 (936 tracks)\n",
      "   â€¢ ChillSunHop V2 (882 tracks)\n",
      "   â€¢ HiğŸ€ (765 tracks)\n",
      "   â€¢ Echo3 (724 tracks)\n",
      "   â€¢ Ride ğŸš´â€â™‚ï¸ (651 tracks)\n",
      "   â€¢ StylinğŸ¤™ (634 tracks)\n",
      "   â€¢ WatsUrFlvr? V3 (616 tracks)\n",
      "   â€¢ RvRChrls3 ğŸ¦¦ (561 tracks)\n",
      "   â€¢ 2Silk2Velvet (524 tracks)\n",
      "   â€¢ GLyD3 (515 tracks)\n",
      "   â€¢ WUT4 (507 tracks)\n",
      "   â€¢ IcedLemonadeğŸ‹ (503 tracks)\n",
      "   â€¢ OnDStreetğŸš¦ (496 tracks)\n",
      "   â€¢ Jams ğŸ“ (491 tracks)\n",
      "   â€¢ SummerChill ğŸŒğŸ¥¶ (458 tracks)\n",
      "   â€¢ FeelDForce âš¡ï¸ (442 tracks)\n",
      "   â€¢ PWR4 (433 tracks)\n",
      "   â€¢ Ghar2ğŸ¡ (424 tracks)\n",
      "   â€¢ Groove/w/Me//3 (422 tracks)\n",
      "   â€¢ hikerboi3 (405 tracks)\n",
      "   â€¢ DunceğŸª© (403 tracks)\n",
      "   â€¢ Flwrs4UğŸŒ¸ (397 tracks)\n",
      "   â€¢ Alt4 (376 tracks)\n",
      "   ... and 16 more playlists\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š AGGRESSIVE REORGANIZATION SUMMARY\n",
      "================================================================================\n",
      "   Current user-created playlists: 64\n",
      "   Auto-generated 'AJ' playlists excluded: 46 (managed by sync script)\n",
      "   Safe deletions (0 tracks lost): 0\n",
      "   Merge consolidations (zero loss after merge): 23\n",
      "   User-created playlists to keep: 41\n",
      "   Final user-created playlist count: 41\n",
      "   Total reduction: 23 playlists (35.9% of user-created)\n",
      "   Total tracks to add: 968 (zero information loss)\n",
      "   âœ… ALL ACTIONS: Zero information loss - all tracks preserved via merge operations\n",
      "   âœ… EXCLUSIONS: Auto-generated 'AJ' playlists excluded from all recommendations\n"
     ]
    }
   ],
   "source": [
    "# Build reorganization plan\n",
    "reorganization_plan = {\n",
    "    'delete': [],\n",
    "    'merge': [],\n",
    "    'keep': []\n",
    "}\n",
    "\n",
    "# Categorize all playlists\n",
    "all_playlist_ids = set(playlist_track_sets.keys())\n",
    "to_delete_ids = safe_to_delete\n",
    "to_keep_ids = all_playlist_ids - to_delete_ids\n",
    "\n",
    "# Build merge groups\n",
    "merge_groups = defaultdict(list)\n",
    "for suggestion in consolidation_suggestions:\n",
    "    if suggestion['action'] == 'merge':\n",
    "        keep_name = suggestion['alternative'].split('\"')[1] if '\"' in suggestion['alternative'] else suggestion['alternative']\n",
    "        merge_groups[keep_name].append(suggestion['playlist_name'])\n",
    "\n",
    "# Organize recommendations\n",
    "for suggestion in consolidation_suggestions:\n",
    "    if suggestion['action'] == 'delete':\n",
    "        reorganization_plan['delete'].append({\n",
    "            'name': suggestion['playlist_name'],\n",
    "            'reason': suggestion['reason'],\n",
    "            'alternative': suggestion['alternative']\n",
    "        })\n",
    "    elif suggestion['action'] == 'merge':\n",
    "        reorganization_plan['merge'].append({\n",
    "            'name': suggestion['playlist_name'],\n",
    "            'reason': suggestion['reason'],\n",
    "            'merge_into': suggestion['alternative'],\n",
    "            'tracks_to_add': suggestion['tracks_lost']\n",
    "        })\n",
    "\n",
    "# Keep all others (user-created playlists only - auto-generated already excluded)\n",
    "for pid in to_keep_ids:\n",
    "    # Double-check: exclude auto-generated playlists (shouldn't be here, but safety check)\n",
    "    if pid not in playlist_info or is_auto_generated_playlist(pid):\n",
    "        continue\n",
    "    info = playlist_info[pid]\n",
    "    reorganization_plan['keep'].append({\n",
    "        'name': info['name'],\n",
    "        'track_count': info['track_count']\n",
    "    })\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ“‹ AGGRESSIVE REORGANIZATION PLAN (Zero Information Loss)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nğŸ—‘ï¸  DELETE ({len(reorganization_plan['delete'])} playlists - 0 tracks lost):\")\n",
    "print(\"-\" * 80)\n",
    "for item in reorganization_plan['delete'][:30]:  # Show top 30\n",
    "    print(f\"   â€¢ {item['name']}\")\n",
    "    print(f\"     â†’ {item['reason']}\")\n",
    "    print(f\"     â†’ Keep: {item['alternative']}\")\n",
    "if len(reorganization_plan['delete']) > 30:\n",
    "    print(f\"\\n   ... and {len(reorganization_plan['delete']) - 30} more safe deletions\")\n",
    "print()\n",
    "\n",
    "print(f\"\\nğŸ”€ MERGE ({len(reorganization_plan['merge'])} playlists - Zero loss after merge):\")\n",
    "print(\"-\" * 80)\n",
    "# Group by target\n",
    "merge_by_target = defaultdict(list)\n",
    "for item in reorganization_plan['merge']:\n",
    "    target = item['merge_into'].split('\"')[1] if '\"' in item['merge_into'] else item['merge_into']\n",
    "    merge_by_target[target].append(item)\n",
    "\n",
    "# Show top groups\n",
    "for target, items in sorted(merge_by_target.items(), key=lambda x: len(x[1]), reverse=True)[:15]:\n",
    "    print(f\"\\n   ğŸ“¦ Target: {target}\")\n",
    "    print(f\"      â†’ Consolidate {len(items)} playlists into this one:\")\n",
    "    total_tracks_to_add = sum(item['tracks_to_add'] for item in items)\n",
    "    for item in items[:5]:  # Show first 5 in group\n",
    "        print(f\"        â€¢ {item['name']} ({item['reason']})\")\n",
    "        if item['tracks_to_add'] > 0:\n",
    "            print(f\"          â†’ Add {item['tracks_to_add']} tracks\")\n",
    "    if len(items) > 5:\n",
    "        print(f\"        ... and {len(items) - 5} more playlists\")\n",
    "    if total_tracks_to_add > 0:\n",
    "        print(f\"      â†’ Total: Add {total_tracks_to_add} tracks (zero loss)\")\n",
    "    else:\n",
    "        print(f\"      â†’ Total: Perfect merge (0 tracks to add)\")\n",
    "\n",
    "if len(merge_by_target) > 15:\n",
    "    print(f\"\\n   ... and {len(merge_by_target) - 15} more merge targets\")\n",
    "print()\n",
    "\n",
    "print(f\"\\nâœ… KEEP ({len(reorganization_plan['keep'])} playlists after consolidation):\")\n",
    "print(\"-\" * 80)\n",
    "# Sort by track count\n",
    "keep_sorted = sorted(reorganization_plan['keep'], key=lambda x: x['track_count'], reverse=True)\n",
    "for item in keep_sorted[:25]:  # Show top 25\n",
    "    print(f\"   â€¢ {item['name']} ({item['track_count']} tracks)\")\n",
    "if len(keep_sorted) > 25:\n",
    "    print(f\"   ... and {len(keep_sorted) - 25} more playlists\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ“Š AGGRESSIVE REORGANIZATION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "total_delete = len(reorganization_plan['delete'])\n",
    "total_merge = len(reorganization_plan['merge'])\n",
    "total_keep = len(reorganization_plan['keep'])\n",
    "total_tracks_to_add = sum(item['tracks_to_add'] for item in reorganization_plan['merge'])\n",
    "final_count = total_keep\n",
    "\n",
    "print(f\"   Current user-created playlists: {len(playlist_info)}\")\n",
    "# Calculate excluded count if not already defined\n",
    "try:\n",
    "    excluded_display = f\"{excluded_count} (managed by sync script)\"\n",
    "except NameError:\n",
    "    # Count auto-generated playlists from playlist_info if excluded_count not available\n",
    "    excluded_display = \"count unavailable (check earlier cells)\"\n",
    "print(f\"   Auto-generated 'AJ' playlists excluded: {excluded_display}\")\n",
    "print(f\"   Safe deletions (0 tracks lost): {total_delete}\")\n",
    "print(f\"   Merge consolidations (zero loss after merge): {total_merge}\")\n",
    "print(f\"   User-created playlists to keep: {total_keep}\")\n",
    "print(f\"   Final user-created playlist count: {final_count}\")\n",
    "print(f\"   Total reduction: {total_delete + total_merge} playlists ({100*(total_delete + total_merge)/len(playlist_info):.1f}% of user-created)\")\n",
    "print(f\"   Total tracks to add: {total_tracks_to_add} (zero information loss)\")\n",
    "print(f\"   âœ… ALL ACTIONS: Zero information loss - all tracks preserved via merge operations\")\n",
    "print(f\"   âœ… EXCLUSIONS: Auto-generated 'AJ' playlists excluded from all recommendations\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Recommendations exported to: /Users/aryamaan/Desktop/Projects/SPOTIM8/data/playlist_consolidation_recommendations.csv\n",
      "\n",
      "ğŸ“Š Summary:\n",
      "   Total recommendations: 23\n",
      "   Safe deletions (0 tracks lost): 0\n",
      "   Merge recommendations: 23\n",
      "\n",
      "ğŸ’¡ Next steps:\n",
      "   1. Review the CSV file: /Users/aryamaan/Desktop/Projects/SPOTIM8/data/playlist_consolidation_recommendations.csv\n",
      "   2. Manually verify recommendations\n",
      "   3. Delete/merge playlists in Spotify\n",
      "   4. Re-run sync to update your library\n"
     ]
    }
   ],
   "source": [
    "# Export recommendations to CSV\n",
    "export_df = pd.DataFrame(consolidation_suggestions)\n",
    "\n",
    "# Add track counts using playlist_id\n",
    "export_df['track_count'] = export_df['playlist_id'].apply(\n",
    "    lambda pid: playlist_info.get(pid, {}).get('track_count', 0)\n",
    ")\n",
    "\n",
    "# Reorder columns\n",
    "export_df = export_df[['playlist_name', 'track_count', 'action', 'reason', 'tracks_lost', 'alternative']]\n",
    "\n",
    "# Save to CSV\n",
    "output_file = DATA_DIR / 'playlist_consolidation_recommendations.csv'\n",
    "export_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"âœ… Recommendations exported to: {output_file}\")\n",
    "print(f\"\\nğŸ“Š Summary:\")\n",
    "print(f\"   Total recommendations: {len(export_df)}\")\n",
    "print(f\"   Safe deletions (0 tracks lost): {len(export_df[export_df['tracks_lost'] == 0])}\")\n",
    "print(f\"   Merge recommendations: {len(export_df[export_df['action'] == 'merge'])}\")\n",
    "print(f\"\\nğŸ’¡ Next steps:\")\n",
    "print(f\"   1. Review the CSV file: {output_file}\")\n",
    "print(f\"   2. Manually verify recommendations\")\n",
    "print(f\"   3. Delete/merge playlists in Spotify\")\n",
    "print(f\"   4. Re-run sync to update your library\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ“Š LISTENING-BASED REDUNDANCY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Playlist Usage Analysis:\n",
      "   (Playlists where tracks are actually played vs. just saved)\n",
      "\n",
      "   âœ… All playlists have good usage rates!\n",
      "\n",
      "\n",
      "ğŸ“Š Listening-Weighted Similarity Analysis:\n",
      "   (Playlists with similar listening patterns, even if track overlap is low)\n",
      "\n",
      "ğŸ”— FUNCTIONALLY REDUNDANT PLAYLISTS (126 pairs):\n",
      "   (Different tracks but similar listening patterns)\n",
      "\n",
      "   â€¢ ChillSunHop V2 â†” TrapNeverDies3.0\n",
      "     Track overlap: 53.6%, Listening similarity: 83.1%\n",
      "   â€¢ IcedLemonadeğŸ‹ â†” SummerChill ğŸŒğŸ¥¶\n",
      "     Track overlap: 49.5%, Listening similarity: 75.1%\n",
      "   â€¢ Chill Dance â†” Ghar2ğŸ¡\n",
      "     Track overlap: 49.9%, Listening similarity: 75.0%\n",
      "   â€¢ IcedLemonadeğŸ‹ â†” RvRChrls3 ğŸ¦¦\n",
      "     Track overlap: 52.7%, Listening similarity: 74.5%\n",
      "   â€¢ WatsUrFlvr? V3 â†” RvRChrls3 ğŸ¦¦\n",
      "     Track overlap: 47.9%, Listening similarity: 74.4%\n",
      "   â€¢ FeelDForce âš¡ï¸ â†” PWR4\n",
      "     Track overlap: 43.7%, Listening similarity: 74.2%\n",
      "   â€¢ StylinğŸ¤™ â†” WatsUrFlvr? V3\n",
      "     Track overlap: 45.0%, Listening similarity: 72.6%\n",
      "   â€¢ ChillSunHop V2 â†” HiğŸ€\n",
      "     Track overlap: 43.3%, Listening similarity: 72.4%\n",
      "   â€¢ InMyRoom ğŸ’½ â†” Flwrs4UğŸŒ¸\n",
      "     Track overlap: 44.8%, Listening similarity: 70.2%\n",
      "   â€¢ ChillSunHop V2 â†” SandTrap ğŸï¸ğŸ‡¹ğŸ‡­\n",
      "     Track overlap: 33.7%, Listening similarity: 68.1%\n",
      "   ... and 116 more pairs\n",
      "\n",
      "ğŸ’¡ Recommendations:\n",
      "   â€¢ Consider deleting unused playlists (0% usage)\n",
      "   â€¢ Review low usage playlists - they may be outdated\n",
      "   â€¢ Functionally redundant playlists might be merged even with low track overlap\n"
     ]
    }
   ],
   "source": [
    "from notebook_helpers import jaccard_similarity\n",
    "\n",
    "# Load streaming history if available\n",
    "from spotim8 import load_streaming_history\n",
    "\n",
    "history_df = load_streaming_history(DATA_DIR)\n",
    "\n",
    "if history_df is not None and len(history_df) > 0:\n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸ“Š LISTENING-BASED REDUNDANCY ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Build track usage map (which tracks are actually played)\n",
    "    played_tracks = set()\n",
    "    if 'track_id' in history_df.columns:\n",
    "        played_tracks = set(history_df['track_id'].dropna().unique())\n",
    "    else:\n",
    "        # Match by artist + track name\n",
    "        played_track_names = set(zip(\n",
    "            history_df['artist_name'].str.lower().fillna(''),\n",
    "            history_df['track_name'].str.lower().fillna('')\n",
    "        ))\n",
    "        # Match with library tracks\n",
    "        # Load tracks and artists if not already loaded\n",
    "        if 'tracks' not in locals() or 'track_artists' not in locals() or 'artists' not in locals():\n",
    "            tracks = pd.read_parquet(DATA_DIR / \"tracks.parquet\")\n",
    "            track_artists = pd.read_parquet(DATA_DIR / \"track_artists.parquet\")\n",
    "            artists = pd.read_parquet(DATA_DIR / \"artists.parquet\")\n",
    "        \n",
    "        library_track_names = tracks.merge(\n",
    "            track_artists[track_artists['position'] == 0],\n",
    "            on='track_id'\n",
    "        ).merge(artists[['artist_id', 'name']], on='artist_id')\n",
    "        library_track_set = set(zip(\n",
    "            library_track_names['name_x'].str.lower().fillna(''),\n",
    "            library_track_names['name_y'].str.lower().fillna('')\n",
    "        ))\n",
    "        # Get track IDs for played tracks\n",
    "        matched = library_track_names[\n",
    "            library_track_names.apply(\n",
    "                lambda row: (row['name_x'].lower(), row['name_y'].lower()) in played_track_names,\n",
    "                axis=1\n",
    "            )\n",
    "        ]\n",
    "        played_tracks = set(matched['track_id'].unique())\n",
    "    \n",
    "    # Analyze playlist usage\n",
    "    print(\"\\nğŸ“Š Playlist Usage Analysis:\")\n",
    "    print(\"   (Playlists where tracks are actually played vs. just saved)\\n\")\n",
    "    \n",
    "    unused_playlists = []\n",
    "    low_usage_playlists = []\n",
    "    \n",
    "    for pid in playlist_track_sets.keys():\n",
    "        playlist_tracks_set = playlist_track_sets[pid]\n",
    "        if not playlist_tracks_set:\n",
    "            continue\n",
    "        \n",
    "        # Count how many tracks from this playlist were actually played\n",
    "        played_from_playlist = playlist_tracks_set & played_tracks\n",
    "        usage_rate = len(played_from_playlist) / len(playlist_tracks_set) if playlist_tracks_set else 0\n",
    "        \n",
    "        info = playlist_info[pid]\n",
    "        \n",
    "        if usage_rate == 0:\n",
    "            unused_playlists.append((pid, info['name'], len(playlist_tracks_set)))\n",
    "        elif usage_rate < 0.1:  # Less than 10% usage\n",
    "            low_usage_playlists.append((pid, info['name'], len(playlist_tracks_set), usage_rate * 100))\n",
    "    \n",
    "    if unused_playlists:\n",
    "        print(f\"ğŸ—‘ï¸  UNUSED PLAYLISTS ({len(unused_playlists)} playlists - 0% tracks played):\")\n",
    "        for pid, name, track_count in sorted(unused_playlists, key=lambda x: x[2], reverse=True)[:10]:\n",
    "            print(f\"   â€¢ {name} ({track_count} tracks) - Never played from\")\n",
    "        if len(unused_playlists) > 10:\n",
    "            print(f\"   ... and {len(unused_playlists) - 10} more\")\n",
    "    \n",
    "    if low_usage_playlists:\n",
    "        print(f\"\\nâš ï¸  LOW USAGE PLAYLISTS ({len(low_usage_playlists)} playlists - <10% tracks played):\")\n",
    "        for pid, name, track_count, usage_pct in sorted(low_usage_playlists, key=lambda x: x[3])[:10]:\n",
    "            print(f\"   â€¢ {name} ({track_count} tracks) - {usage_pct:.1f}% usage\")\n",
    "        if len(low_usage_playlists) > 10:\n",
    "            print(f\"   ... and {len(low_usage_playlists) - 10} more\")\n",
    "    \n",
    "    if not unused_playlists and not low_usage_playlists:\n",
    "        print(\"   âœ… All playlists have good usage rates!\")\n",
    "    \n",
    "    # Listening-weighted similarity\n",
    "    print(\"\\n\\nğŸ“Š Listening-Weighted Similarity Analysis:\")\n",
    "    print(\"   (Playlists with similar listening patterns, even if track overlap is low)\\n\")\n",
    "    \n",
    "    # Build listening frequency per track\n",
    "    track_listen_counts = {}\n",
    "    if 'track_id' in history_df.columns:\n",
    "        track_listen_counts = history_df.groupby('track_id').size().to_dict()\n",
    "    else:\n",
    "        # Count by artist + track name\n",
    "        track_name_counts = history_df.groupby(['artist_name', 'track_name']).size()\n",
    "        # Match to track IDs\n",
    "        for (artist, track), count in track_name_counts.items():\n",
    "            # Load tracks and artists if not already loaded\n",
    "            if 'tracks' not in locals() or 'track_artists' not in locals() or 'artists' not in locals():\n",
    "                tracks = pd.read_parquet(DATA_DIR / \"tracks.parquet\")\n",
    "                track_artists = pd.read_parquet(DATA_DIR / \"track_artists.parquet\")\n",
    "                artists = pd.read_parquet(DATA_DIR / \"artists.parquet\")\n",
    "            \n",
    "            matches = tracks.merge(\n",
    "                track_artists[track_artists['position'] == 0],\n",
    "                on='track_id'\n",
    "            ).merge(artists[['artist_id', 'name']], on='artist_id')\n",
    "            matches = matches[\n",
    "                (matches['name_x'].str.lower() == track.lower()) &\n",
    "                (matches['name_y'].str.lower() == artist.lower())\n",
    "            ]\n",
    "            if len(matches) > 0:\n",
    "                track_listen_counts[matches.iloc[0]['track_id']] = count\n",
    "    \n",
    "    # Calculate listening-weighted similarity\n",
    "    listening_redundant = []\n",
    "    for i, (pid1, set1) in enumerate(playlist_track_sets.items()):\n",
    "        if not set1:\n",
    "            continue\n",
    "        for j, (pid2, set2) in enumerate(playlist_track_sets.items()):\n",
    "            if i >= j or not set2:\n",
    "                continue\n",
    "            \n",
    "            # Get shared tracks\n",
    "            shared = set1 & set2\n",
    "            if not shared:\n",
    "                continue\n",
    "            \n",
    "            # Calculate listening-weighted similarity\n",
    "            shared_listens = sum(track_listen_counts.get(tid, 0) for tid in shared)\n",
    "            total_listens_1 = sum(track_listen_counts.get(tid, 0) for tid in set1)\n",
    "            total_listens_2 = sum(track_listen_counts.get(tid, 0) for tid in set2)\n",
    "            \n",
    "            if total_listens_1 == 0 or total_listens_2 == 0:\n",
    "                continue\n",
    "            \n",
    "            # Similarity based on shared listening frequency\n",
    "            listening_sim = shared_listens / max(total_listens_1, total_listens_2)\n",
    "            \n",
    "            # Also check traditional Jaccard\n",
    "            jaccard = jaccard_similarity(set1, set2)\n",
    "            \n",
    "            # If listening similarity is high but Jaccard is low, they serve similar purpose\n",
    "            if listening_sim > 0.5 and jaccard < 0.7:\n",
    "                info1 = playlist_info[pid1]\n",
    "                info2 = playlist_info[pid2]\n",
    "                listening_redundant.append((pid1, pid2, info1['name'], info2['name'], jaccard, listening_sim))\n",
    "    \n",
    "    if listening_redundant:\n",
    "        print(f\"ğŸ”— FUNCTIONALLY REDUNDANT PLAYLISTS ({len(listening_redundant)} pairs):\")\n",
    "        print(\"   (Different tracks but similar listening patterns)\\n\")\n",
    "        for pid1, pid2, name1, name2, jaccard, listening_sim in sorted(listening_redundant, key=lambda x: x[5], reverse=True)[:10]:\n",
    "            print(f\"   â€¢ {name1} â†” {name2}\")\n",
    "            print(f\"     Track overlap: {jaccard*100:.1f}%, Listening similarity: {listening_sim*100:.1f}%\")\n",
    "        if len(listening_redundant) > 10:\n",
    "            print(f\"   ... and {len(listening_redundant) - 10} more pairs\")\n",
    "    else:\n",
    "        print(\"   âœ… No functionally redundant playlists found based on listening patterns\")\n",
    "    \n",
    "    print(\"\\nğŸ’¡ Recommendations:\")\n",
    "    print(\"   â€¢ Consider deleting unused playlists (0% usage)\")\n",
    "    print(\"   â€¢ Review low usage playlists - they may be outdated\")\n",
    "    print(\"   â€¢ Functionally redundant playlists might be merged even with low track overlap\")\n",
    "else:\n",
    "    print(\"âš ï¸  No streaming history data available\")\n",
    "    print(\"   Run the streaming history sync in 04_analyze_listening_history.ipynb to enable this analysis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”€ Generate Merge Commands (Using Merge Logic from Examples)\n",
    "\n",
    "This cell identifies potential merges using the merge logic pattern:\n",
    "1. Determine which playlist is older (by earliest track added_at timestamp)\n",
    "2. Use the older playlist as the source (it will be renamed)\n",
    "3. Merge tracks from newer playlists into the older one\n",
    "4. Delete the newer playlists after merge\n",
    "\n",
    "Based on the redundancy analysis, we'll identify merges from:\n",
    "- Subsets (fully contained playlists)\n",
    "- High overlap pairs (>70% similarity)\n",
    "- Near-duplicates (50-70% similarity with size differences)\n",
    "- Merge candidates (small playlists with high overlap in larger ones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ”€ MERGE SUGGESTIONS (Using Merge Logic Pattern)\n",
      "================================================================================\n",
      "\n",
      "1ï¸âƒ£ SUBSETS (merge subset into superset):\n",
      "\n",
      "\n",
      "2ï¸âƒ£ HIGH OVERLAP PAIRS (>70% similarity):\n",
      "\n",
      "\n",
      "3ï¸âƒ£ TOP MERGE CANDIDATES (small â†’ large, showing top 10):\n",
      "\n",
      "   â€¢ Jan26 â†’ InMyRoom ğŸ’½ (overlap: 71.7%, add 26 tracks)\n",
      "     Command: python scripts/merge_to_new_playlist.py \"InMyRoom ğŸ’½\" \"Jan26\" \"InMyRoom ğŸ’½\"\n",
      "   â€¢ Jan26 â†’ Jams ğŸ“ (overlap: 71.7%, add 26 tracks)\n",
      "     Command: python scripts/merge_to_new_playlist.py \"Jams ğŸ“\" \"Jan26\" \"Jams ğŸ“\"\n",
      "   â€¢ Jan26 â†’ Ride ğŸš´â€â™‚ï¸ (overlap: 73.9%, add 24 tracks)\n",
      "     Command: python scripts/merge_to_new_playlist.py \"Ride ğŸš´â€â™‚ï¸\" \"Jan26\" \"Ride ğŸš´â€â™‚ï¸\"\n",
      "   â€¢ Jan26 â†’ HiğŸ€ (overlap: 60.9%, add 36 tracks)\n",
      "     Command: python scripts/merge_to_new_playlist.py \"HiğŸ€\" \"Jan26\" \"HiğŸ€\"\n",
      "   â€¢ Jan26 â†’ StylinğŸ¤™ (overlap: 73.9%, add 24 tracks)\n",
      "     Command: python scripts/merge_to_new_playlist.py \"StylinğŸ¤™\" \"Jan26\" \"StylinğŸ¤™\"\n",
      "   â€¢ Jan26 â†’ GLyD3 (overlap: 57.6%, add 39 tracks)\n",
      "     Command: python scripts/merge_to_new_playlist.py \"GLyD3\" \"Jan26\" \"GLyD3\"\n",
      "   â€¢ Jan26 â†’ DunceğŸª© (overlap: 57.6%, add 39 tracks)\n",
      "     Command: python scripts/merge_to_new_playlist.py \"DunceğŸª©\" \"Jan26\" \"DunceğŸª©\"\n",
      "   â€¢ Jan26 â†’ WatsUrFlvr? V3 (overlap: 62.0%, add 35 tracks)\n",
      "     Command: python scripts/merge_to_new_playlist.py \"WatsUrFlvr? V3\" \"Jan26\" \"WatsUrFlvr? V3\"\n",
      "   â€¢ Trapsoul â†’ InMyRoom ğŸ’½ (overlap: 84.2%, add 9 tracks)\n",
      "     Command: python scripts/merge_to_new_playlist.py \"InMyRoom ğŸ’½\" \"Trapsoul\" \"InMyRoom ğŸ’½\"\n",
      "   â€¢ Trapsoul â†’ Jams ğŸ“ (overlap: 75.4%, add 14 tracks)\n",
      "     Command: python scripts/merge_to_new_playlist.py \"Jams ğŸ“\" \"Trapsoul\" \"Jams ğŸ“\"\n",
      "\n",
      "âœ… Generated 10 merge suggestions\n",
      "   (Subsets: 0)\n",
      "   (High overlap: 0)\n",
      "   (Merge candidates shown: 10)\n",
      "\n",
      "ğŸ’¡ Note: Commands use the older playlist as source (following merge logic pattern)\n",
      "   All suggestions preserve tracks - zero information loss\n"
     ]
    }
   ],
   "source": [
    "# Load playlist tracks to determine playlist age\n",
    "playlist_tracks_df = pd.read_parquet(DATA_DIR / \"playlist_tracks.parquet\")\n",
    "\n",
    "def get_playlist_earliest_timestamp(playlist_id: str) -> pd.Timestamp:\n",
    "    \"\"\"Get the earliest added_at timestamp for a playlist.\"\"\"\n",
    "    pl_tracks = playlist_tracks_df[playlist_tracks_df['playlist_id'] == playlist_id].copy()\n",
    "    if len(pl_tracks) == 0:\n",
    "        return pd.Timestamp.max  # If no tracks, consider it newest\n",
    "    pl_tracks['added_at'] = pd.to_datetime(pl_tracks['added_at'], errors='coerce', utc=True)\n",
    "    earliest = pl_tracks['added_at'].min()\n",
    "    if pd.isna(earliest):\n",
    "        return pd.Timestamp.max  # If no valid timestamps, consider it newest\n",
    "    return earliest\n",
    "\n",
    "# Build merge suggestions using the merge logic pattern\n",
    "merge_suggestions = []\n",
    "\n",
    "# 1. Subsets - merge into the superset (which is older by definition if it contains all tracks)\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ”€ MERGE SUGGESTIONS (Using Merge Logic Pattern)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n1ï¸âƒ£ SUBSETS (merge subset into superset):\\n\")\n",
    "for subset_pid, superset_pid, subset_size, superset_size in subsets:\n",
    "    subset_info = playlist_info[subset_pid]\n",
    "    superset_info = playlist_info[superset_pid]\n",
    "    \n",
    "    # Determine which is older\n",
    "    subset_earliest = get_playlist_earliest_timestamp(subset_pid)\n",
    "    superset_earliest = get_playlist_earliest_timestamp(superset_pid)\n",
    "    \n",
    "    if subset_earliest <= superset_earliest:\n",
    "        older_name = subset_info['name']\n",
    "        older_id = subset_pid\n",
    "        newer_name = superset_info['name']\n",
    "        newer_id = superset_pid\n",
    "        new_name = superset_info['name']  # Keep the superset name\n",
    "    else:\n",
    "        older_name = superset_info['name']\n",
    "        older_id = superset_pid\n",
    "        newer_name = subset_info['name']\n",
    "        newer_id = subset_pid\n",
    "        new_name = superset_info['name']  # Keep the superset name\n",
    "    \n",
    "    merge_suggestions.append({\n",
    "        'type': 'subset',\n",
    "        'older_playlist': older_name,\n",
    "        'newer_playlist': newer_name,\n",
    "        'new_name': new_name,\n",
    "        'older_id': older_id,\n",
    "        'newer_id': newer_id,\n",
    "        'tracks_in_older': playlist_info[older_id]['track_count'],\n",
    "        'tracks_in_newer': playlist_info[newer_id]['track_count'],\n",
    "        'command': f'python scripts/merge_to_new_playlist.py \"{older_name}\" \"{newer_name}\" \"{new_name}\"'\n",
    "    })\n",
    "    \n",
    "    print(f\"   â€¢ {subset_info['name']} â†’ {superset_info['name']}\")\n",
    "    print(f\"     Command: python scripts/merge_to_new_playlist.py \\\"{subset_info['name']}\\\" \\\"{superset_info['name']}\\\" \\\"{superset_info['name']}\\\"\")\n",
    "\n",
    "# 2. High overlap pairs - merge smaller into larger (determine older for target)\n",
    "print(\"\\n2ï¸âƒ£ HIGH OVERLAP PAIRS (>70% similarity):\\n\")\n",
    "for pid1, pid2, jaccard, overlap1, overlap2 in high_overlap:\n",
    "    info1 = playlist_info[pid1]\n",
    "    info2 = playlist_info[pid2]\n",
    "    \n",
    "    # Determine which is older\n",
    "    pid1_earliest = get_playlist_earliest_timestamp(pid1)\n",
    "    pid2_earliest = get_playlist_earliest_timestamp(pid2)\n",
    "    \n",
    "    if pid1_earliest <= pid2_earliest:\n",
    "        older_name = info1['name']\n",
    "        older_id = pid1\n",
    "        newer_name = info2['name']\n",
    "        newer_id = pid2\n",
    "    else:\n",
    "        older_name = info2['name']\n",
    "        older_id = pid2\n",
    "        newer_name = info1['name']\n",
    "        newer_id = pid1\n",
    "    \n",
    "    # Use the larger playlist name as the new name\n",
    "    if info1['track_count'] >= info2['track_count']:\n",
    "        new_name = info1['name']\n",
    "    else:\n",
    "        new_name = info2['name']\n",
    "    \n",
    "    merge_suggestions.append({\n",
    "        'type': 'high_overlap',\n",
    "        'older_playlist': older_name,\n",
    "        'newer_playlist': newer_name,\n",
    "        'new_name': new_name,\n",
    "        'older_id': older_id,\n",
    "        'newer_id': newer_id,\n",
    "        'similarity': f\"{jaccard*100:.1f}%\",\n",
    "        'command': f'python scripts/merge_to_new_playlist.py \"{older_name}\" \"{newer_name}\" \"{new_name}\"'\n",
    "    })\n",
    "    \n",
    "    print(f\"   â€¢ {info1['name']} + {info2['name']} (similarity: {jaccard*100:.1f}%)\")\n",
    "    print(f\"     Command: python scripts/merge_to_new_playlist.py \\\"{older_name}\\\" \\\"{newer_name}\\\" \\\"{new_name}\\\"\")\n",
    "\n",
    "# 3. Top merge candidates - merge small into large\n",
    "print(\"\\n3ï¸âƒ£ TOP MERGE CANDIDATES (small â†’ large, showing top 10):\\n\")\n",
    "for small_pid, large_pid, small_overlap, large_overlap, small_size, large_size in merge_candidates[:10]:\n",
    "    small_info = playlist_info[small_pid]\n",
    "    large_info = playlist_info[large_pid]\n",
    "    \n",
    "    # Determine which is older\n",
    "    small_earliest = get_playlist_earliest_timestamp(small_pid)\n",
    "    large_earliest = get_playlist_earliest_timestamp(large_pid)\n",
    "    \n",
    "    if small_earliest <= large_earliest:\n",
    "        older_name = small_info['name']\n",
    "        older_id = small_pid\n",
    "        newer_name = large_info['name']\n",
    "        newer_id = large_pid\n",
    "    else:\n",
    "        older_name = large_info['name']\n",
    "        older_id = large_pid\n",
    "        newer_name = small_info['name']\n",
    "        newer_id = small_pid\n",
    "    \n",
    "    # Use the larger playlist name as the new name\n",
    "    new_name = large_info['name']\n",
    "    \n",
    "    missing_tracks = len(playlist_track_sets[small_pid] - playlist_track_sets[large_pid])\n",
    "    \n",
    "    merge_suggestions.append({\n",
    "        'type': 'merge_candidate',\n",
    "        'older_playlist': older_name,\n",
    "        'newer_playlist': newer_name,\n",
    "        'new_name': new_name,\n",
    "        'older_id': older_id,\n",
    "        'newer_id': newer_id,\n",
    "        'overlap': f\"{small_overlap*100:.1f}%\",\n",
    "        'tracks_to_add': missing_tracks,\n",
    "        'command': f'python scripts/merge_to_new_playlist.py \"{older_name}\" \"{newer_name}\" \"{new_name}\"'\n",
    "    })\n",
    "    \n",
    "    print(f\"   â€¢ {small_info['name']} â†’ {large_info['name']} (overlap: {small_overlap*100:.1f}%, add {missing_tracks} tracks)\")\n",
    "    print(f\"     Command: python scripts/merge_to_new_playlist.py \\\"{older_name}\\\" \\\"{newer_name}\\\" \\\"{new_name}\\\"\")\n",
    "\n",
    "print(f\"\\nâœ… Generated {len(merge_suggestions)} merge suggestions\")\n",
    "print(f\"   (Subsets: {len([m for m in merge_suggestions if m['type'] == 'subset'])})\")\n",
    "print(f\"   (High overlap: {len([m for m in merge_suggestions if m['type'] == 'high_overlap'])})\")\n",
    "print(f\"   (Merge candidates shown: {len([m for m in merge_suggestions if m['type'] == 'merge_candidate'])})\")\n",
    "print(f\"\\nğŸ’¡ Note: Commands use the older playlist as source (following merge logic pattern)\")\n",
    "print(f\"   All suggestions preserve tracks - zero information loss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Done!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Done! (Aggressive Consolidation Complete)\n",
    "\n",
    "**Summary (AGGRESSIVE MODE):**\n",
    "- âœ… Identified redundant playlists using **aggressive thresholds** (>50% similarity)\n",
    "- âœ… Found playlists safe to delete (zero track loss)\n",
    "- âœ… **FORCED suggestions** for high-overlap playlists (>70% similarity)\n",
    "- âœ… Suggested merge strategies for near-duplicates (>50% similarity with size difference)\n",
    "- âœ… Identified size-based merge candidates (3x+ smaller with >50% overlap)\n",
    "- âœ… Found group consolidation opportunities (multiple small playlists â†’ one larger)\n",
    "- âœ… Created aggressive reorganization plan\n",
    "- âœ… Exported recommendations to CSV\n",
    "\n",
    "**Key Metrics:**\n",
    "- **Lowered thresholds** for maximum consolidation without loss\n",
    "- **Zero information loss**: All suggestions preserve tracks via merge operations\n",
    "- **Forced suggestions**: Aggressive approach finds more consolidation opportunities\n",
    "\n",
    "**Next Steps:**\n",
    "1. Review the recommendations in the CSV file (`playlist_consolidation_recommendations.csv`)\n",
    "2. **For deletions**: Delete playlists - zero track loss (all tracks in another playlist)\n",
    "3. **For merges**: \n",
    "   - Add missing tracks from smaller playlist to larger playlist\n",
    "   - After merging tracks, delete the smaller playlist\n",
    "   - **Zero loss**: All tracks preserved via merge operations\n",
    "4. Review group consolidation opportunities for batch merges\n",
    "5. Re-run `01_sync_data.ipynb` to update your library\n",
    "6. Re-run this notebook to verify cleanup\n",
    "\n",
    "**Workflow:**\n",
    "- `01_sync_data.ipynb` â†’ `02_analyze_library.ipynb` â†’ `03_playlist_analysis.ipynb` â†’ `04_analyze_listening_history.ipynb` â†’ `05_liked_songs_monthly_playlists.ipynb` â†’ `06_identify_redundant_playlists.ipynb`\n",
    "\n",
    "**Important Notes:**\n",
    "- âœ… **All suggestions preserve information** - zero track loss via merge operations\n",
    "- âš ï¸  Always verify recommendations manually before deleting playlists\n",
    "- ğŸ’¡ Merge operations require adding missing tracks first, then deleting merged playlist\n",
    "- ğŸ“Š Aggressive thresholds ensure maximum playlist reduction while preserving all tracks\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
